{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl7v95qT7vaf"
      },
      "source": [
        "# Installations :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK8Y1niOFPJO",
        "outputId": "f30b3ccd-b845-4fc4-a2b0-6b6eaa7f7ef9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "pip install gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCt7TOprDdp2"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QEnV1_5LDdp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from gymnasium.wrappers import TimeLimit\n",
        "import gymnasium as gym\n",
        "from statistics import mean\n",
        "from functools import partial\n",
        "from typing import Protocol\n",
        "import random\n",
        "import os\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import torch.nn as nn\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mj0ScOrF7zgL"
      },
      "source": [
        "# Connect to drive to save models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-LdU-vAGxce",
        "outputId": "b723c272-928e-4bf2-8242-a221d021e237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Access the specific folder in your MyDrive\n",
        "path = '/content/drive/MyDrive/MVA/Reinforcement_Learning/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTfyuCYm75JC"
      },
      "source": [
        "# Environnement functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UeHV5le4FCGX"
      },
      "outputs": [],
      "source": [
        "class HIVPatient(gym.Env):\n",
        "    \"\"\"HIV patient simulator\n",
        "\n",
        "    Implements the simulator defined in 'Dynamic Multidrug Therapies for HIV: Optimal and STI Control Approaches' by Adams et al. (2004).\n",
        "    The transition() function allows to simulate continuous time dynamics and control.\n",
        "    The step() function is tailored for the evaluation of Structured Treatment Interruptions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, clipping=True, logscale=False, domain_randomization: bool = False\n",
        "    ):\n",
        "        super(HIVPatient, self).__init__()\n",
        "\n",
        "        self.domain_randomization = domain_randomization\n",
        "        self.action_space = gym.spaces.Discrete(4)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            shape=(6,), low=-np.inf, high=np.inf, dtype=np.float32\n",
        "        )\n",
        "\n",
        "        self.T1 = 163573.0  # healthy type 1 cells concentration (cells per mL)\n",
        "        self.T1star = 11945.0  # infected type 1 cells concentration (cells per mL)\n",
        "        self.T2 = 5.0  # healthy type 2 cells concentration (cells per mL)\n",
        "        self.T2star = 46.0  # infected type 2 cells concentration (cells per mL)\n",
        "        self.V = 63919.0  # free virus (copies per mL)\n",
        "        self.E = 24.0  # immune effector cells concentration (cells per mL)\n",
        "\n",
        "        # actions\n",
        "        self.action_set = [\n",
        "            np.array(pair) for pair in [[0.0, 0.0], [0.0, 0.3], [0.7, 0.0], [0.7, 0.3]]\n",
        "        ]\n",
        "\n",
        "        self._reset_patient_parameters()\n",
        "\n",
        "        # action bounds\n",
        "        self.a1 = 0.0  # lower bound on reverse transcriptase efficacy\n",
        "        self.b1 = 0.7  # lower bound on reverse transcriptase efficacy\n",
        "        self.a2 = 0.0  # lower bound on protease inhibitor efficacy\n",
        "        self.b2 = 0.3  # lower bound on protease inhibitor efficacy\n",
        "\n",
        "        # reward model\n",
        "        self.Q = 0.1\n",
        "        self.R1 = 20000.0\n",
        "        self.R2 = 20000.0\n",
        "        self.S = 1000.0\n",
        "\n",
        "        # options\n",
        "        self.clipping = clipping  # clip the state to the upper and lower bounds (affects the state attributes, which are clipped before being stored in T1, T1star, etc.)\n",
        "        self.logscale = logscale  # convert state to log10-scale before returning (does not affect the state attributes, which remain stored without the log10 operation)\n",
        "        self.T1Upper = 1e6\n",
        "        self.T1starUpper = 5e4\n",
        "        self.T2Upper = 3200.0\n",
        "        self.T2starUpper = 80.0\n",
        "        self.VUpper = 2.5e5\n",
        "        self.EUpper = 353200.0\n",
        "        self.upper = np.array(\n",
        "            [\n",
        "                self.T1Upper,\n",
        "                self.T1starUpper,\n",
        "                self.T2Upper,\n",
        "                self.T2starUpper,\n",
        "                self.VUpper,\n",
        "                self.EUpper,\n",
        "            ]\n",
        "        )\n",
        "        self.T1Lower = 0.0\n",
        "        self.T1starLower = 0.0\n",
        "        self.T2Lower = 0.0\n",
        "        self.T2starLower = 0.0\n",
        "        self.VLower = 0.0\n",
        "        self.ELower = 0.0\n",
        "        self.lower = np.array(\n",
        "            [\n",
        "                self.T1Lower,\n",
        "                self.T1starLower,\n",
        "                self.T2Lower,\n",
        "                self.T2starLower,\n",
        "                self.VLower,\n",
        "                self.ELower,\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def rawstate(self):\n",
        "        return np.array([self.T1, self.T1star, self.T2, self.T2star, self.V, self.E])\n",
        "\n",
        "    def state(self):\n",
        "        s = np.array([self.T1, self.T1star, self.T2, self.T2star, self.V, self.E])\n",
        "        if self.clipping:\n",
        "            np.clip(s, self.lower, self.upper, out=s)\n",
        "        if self.logscale:\n",
        "            s = np.log10(s)\n",
        "        return s\n",
        "\n",
        "    def _reset_patient_parameters(self):\n",
        "        if self.domain_randomization:\n",
        "            # randomly changing patient parameters\n",
        "            self.k1 = np.random.uniform(low=5e-7, high=8e-7)\n",
        "            # cell2\n",
        "            self.k2 = np.random.uniform(low=0.1e-4, high=1.0e-4)\n",
        "            self.f = np.random.uniform(low=0.29, high=0.34)\n",
        "\n",
        "        else:\n",
        "\n",
        "            self.k1 = 8e-7  # infection rate (mL per virions and per day)\n",
        "\n",
        "            self.k2 = 1e-4  # infection rate (mL per virions and per day)\n",
        "            self.f = 0.34  # treatment efficacy reduction for type 2 cells\n",
        "        # patient parameters\n",
        "\n",
        "        # cell type 1\n",
        "        self.lambda1 = 1e4  # production rate (cells per mL and per day)\n",
        "        self.d1 = 1e-2  # death rate (per day)\n",
        "        self.m1 = 1e-5  # immune-induced clearance rate (mL per cells and per day)\n",
        "        self.rho1 = 1  # nb virions infecting a cell (virions per cell)\n",
        "\n",
        "        # cell type 2\n",
        "        self.lambda2 = 31.98  # production rate (cells per mL and per day)\n",
        "        self.d2 = 1e-2  # death rate (per day)\n",
        "        self.m2 = 1e-5  # immune-induced clearance rate (mL per cells and per day)\n",
        "        self.rho2 = 1  # nb virions infecting a cell (virions per cell)\n",
        "        # infected cells\n",
        "        self.delta = 0.7  # death rate (per day)\n",
        "        self.NT = 100  # virions produced (virions per cell)\n",
        "        self.c = 13  # virus natural death rate (per day)\n",
        "        # immune response (immune effector cells)\n",
        "        self.lambdaE = 1  # production rate (cells per mL and per day)\n",
        "        self.bE = 0.3  # maximum birth rate (per day)\n",
        "        self.Kb = 100  # saturation constant for birth (cells per mL)\n",
        "        self.dE = 0.25  # maximum death rate (per day)\n",
        "        self.Kd = 500  # saturation constant for death (cells per mL)\n",
        "        self.deltaE = 0.1  # natural death rate (per day)\n",
        "\n",
        "    def reset(\n",
        "        self, *, seed: int | None = None, options: dict | None = None, mode=\"unhealthy\"\n",
        "    ):\n",
        "        if mode == \"uninfected\":\n",
        "            self.T1 = 1e6\n",
        "            self.T1star = 0.0\n",
        "            self.T2 = 3198.0\n",
        "            self.T2star = 0.0\n",
        "            self.V = 0.0\n",
        "            self.E = 10.0\n",
        "        elif mode == \"unhealthy\":\n",
        "            self.T1 = 163573.0\n",
        "            self.T1star = 11945.0\n",
        "            self.T2 = 5.0\n",
        "            self.T2star = 46.0\n",
        "            self.V = 63919.0\n",
        "            self.E = 24.0\n",
        "        elif mode == \"healthy\":\n",
        "            self.T1 = 967839.0\n",
        "            self.T1star = 76.0\n",
        "            self.T2 = 621.0\n",
        "            self.T2star = 6.0\n",
        "            self.V = 415.0\n",
        "            self.E = 353108.0\n",
        "        else:\n",
        "            print(\"Patient mode '\", mode, \"' unrecognized. State unchanged.\")\n",
        "\n",
        "        self._reset_patient_parameters()\n",
        "\n",
        "        return self.state(), {}\n",
        "\n",
        "    def der(self, state, action):\n",
        "        T1 = state[0]\n",
        "        T1star = state[1]\n",
        "        T2 = state[2]\n",
        "        T2star = state[3]\n",
        "        V = state[4]\n",
        "        E = state[5]\n",
        "\n",
        "        eps1 = action[0]\n",
        "        eps2 = action[1]\n",
        "\n",
        "        T1dot = self.lambda1 - self.d1 * T1 - self.k1 * (1 - eps1) * V * T1\n",
        "\n",
        "        T1stardot = (\n",
        "            self.k1 * (1 - eps1) * V * T1 - self.delta * T1star - self.m1 * E * T1star\n",
        "        )\n",
        "        T2dot = self.lambda2 - self.d2 * T2 - self.k2 * (1 - self.f * eps1) * V * T2\n",
        "        T2stardot = (\n",
        "            self.k2 * (1 - self.f * eps1) * V * T2\n",
        "            - self.delta * T2star\n",
        "            - self.m2 * E * T2star\n",
        "        )\n",
        "        Vdot = (\n",
        "            self.NT * self.delta * (1 - eps2) * (T1star + T2star)\n",
        "            - self.c * V\n",
        "            - (\n",
        "                self.rho1 * self.k1 * (1 - eps1) * T1\n",
        "                + self.rho2 * self.k2 * (1 - self.f * eps1) * T2\n",
        "            )\n",
        "            * V\n",
        "        )\n",
        "        Edot = (\n",
        "            self.lambdaE\n",
        "            + self.bE * (T1star + T2star) * E / (T1star + T2star + self.Kb)\n",
        "            - self.dE * (T1star + T2star) * E / (T1star + T2star + self.Kd)\n",
        "            - self.deltaE * E\n",
        "        )\n",
        "        return np.array([T1dot, T1stardot, T2dot, T2stardot, Vdot, Edot])\n",
        "\n",
        "    def transition(self, state, action, duration):\n",
        "        \"\"\"duration should be a multiple of 1e-3\"\"\"\n",
        "        state0 = np.copy(state)\n",
        "        state0_orig = np.copy(state)\n",
        "        nb_steps = int(duration // 1e-3)\n",
        "        for i in range(nb_steps):\n",
        "            der = self.der(state0, action)\n",
        "            state1 = state0 + der * 1e-3\n",
        "\n",
        "            # np.clip(state1, self.lower, self.upper, out=state1)\n",
        "            state0 = state1\n",
        "        return state1\n",
        "\n",
        "    def reward(self, state, action, state2):\n",
        "        rew = -(\n",
        "            self.Q * state[4]\n",
        "            + self.R1 * action[0] ** 2\n",
        "            + self.R2 * action[1] ** 2\n",
        "            - self.S * state[5]\n",
        "        )\n",
        "        return rew\n",
        "\n",
        "    def step(self, a_index):\n",
        "        state = self.state()\n",
        "        action = self.action_set[a_index]\n",
        "        state2 = self.transition(state, action, 5)\n",
        "        rew = self.reward(state, action, state2)\n",
        "        if self.clipping:\n",
        "            np.clip(state2, self.lower, self.upper, out=state2)\n",
        "\n",
        "        self.T1 = state2[0]\n",
        "        self.T1star = state2[1]\n",
        "        self.T2 = state2[2]\n",
        "        self.T2star = state2[3]\n",
        "        self.V = state2[4]\n",
        "        self.E = state2[5]\n",
        "\n",
        "        if self.logscale:\n",
        "            state2 = np.log10(state2)\n",
        "\n",
        "        return state2, rew, False, False, {}\n",
        "\n",
        "\n",
        "\n",
        "class Agent(Protocol):\n",
        "    \"\"\"\n",
        "    Defines an interface for agents in a simulation or decision-making environment.\n",
        "\n",
        "    An Agent must implement methods to act based on observations, save its state to a file,\n",
        "    and load its state from a file. This interface uses the Protocol class from the typing\n",
        "    module to specify methods that concrete classes must implement.\n",
        "\n",
        "    Protocols are a way to define formal Python interfaces. They allow for type checking\n",
        "    and ensure that implementing classes provide specific methods with the expected signatures.\n",
        "    \"\"\"\n",
        "\n",
        "    def act(self, observation: np.ndarray, use_random: bool = False) -> int:\n",
        "        \"\"\"\n",
        "        Determines the next action based on the current observation from the environment.\n",
        "\n",
        "        Implementing this method requires processing the observation and optionally incorporating\n",
        "        randomness into the decision-making process (e.g., for exploration in reinforcement learning).\n",
        "\n",
        "        Args:\n",
        "            observation (np.ndarray): The current environmental observation that the agent must use\n",
        "                                       to decide its next action. This array typically represents\n",
        "                                       the current state of the environment.\n",
        "            use_random (bool, optional): A flag to indicate whether the agent should make a random\n",
        "                                         decision. This is often used for exploration. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            int: The action to be taken by the agent.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self, path: str) -> None:\n",
        "        \"\"\"\n",
        "        Saves the agent's current state to a file specified by the path.\n",
        "\n",
        "        This method should serialize the agent's state (e.g., model weights, configuration settings)\n",
        "        and save it to a file, allowing the agent to be later restored to this state using the `load` method.\n",
        "\n",
        "        Args:\n",
        "            path (str): The file path where the agent's state should be saved.\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self) -> None:\n",
        "        \"\"\"\n",
        "        Loads the agent's state from a file specified by the path (HARDCODED). This not a good practice,\n",
        "        but it will simplify the grading process.\n",
        "\n",
        "        This method should deserialize the saved state (e.g., model weights, configuration settings)\n",
        "        from the file and restore the agent to this state. Implementations must ensure that the\n",
        "        agent's state is compatible with the `act` method's expectations.\n",
        "\n",
        "        Note:\n",
        "            It's important to ensure that neural network models (if used) are loaded in a way that is\n",
        "            compatible with the execution device (e.g., CPU, GPU). This may require specific handling\n",
        "            depending on the libraries used for model implementation. WARNING: THE GITHUB CLASSROOM\n",
        "        HANDLES ONLY CPU EXECUTION. IF YOU USE A NEURAL NETWORK MODEL, MAKE SURE TO LOAD IT IN A WAY THAT\n",
        "        DOES NOT REQUIRE A GPU.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_agent(agent: Agent, env: gym.Env, nb_episode: int = 10) -> float:\n",
        "    \"\"\"\n",
        "    Evaluate an agent in a given environment.\n",
        "\n",
        "    Args:\n",
        "        agent (Agent): The agent to evaluate.\n",
        "        env (gym.Env): The environment to evaluate the agent in.\n",
        "        nb_episode (int): The number of episode to evaluate the agent.\n",
        "\n",
        "    Returns:\n",
        "        float: The mean reward of the agent over the episodes.\n",
        "    \"\"\"\n",
        "    rewards: list[float] = []\n",
        "    for _ in range(nb_episode):\n",
        "        obs, info = env.reset()\n",
        "        done = False\n",
        "        truncated = False\n",
        "        episode_reward = 0\n",
        "        while not done and not truncated:\n",
        "            action = agent.act(obs)\n",
        "            obs, reward, done, truncated, _ = env.step(action)\n",
        "            episode_reward += reward\n",
        "        rewards.append(episode_reward)\n",
        "    return mean(rewards)\n",
        "\n",
        "\n",
        "evaluate_HIV = partial(\n",
        "    evaluate_agent, env=TimeLimit(HIVPatient(), max_episode_steps=200)\n",
        ")\n",
        "\n",
        "\n",
        "evaluate_HIV_population = partial(\n",
        "    evaluate_agent,\n",
        "    env=TimeLimit(HIVPatient(domain_randomization=True), max_episode_steps=200),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-LKH62T8Qnd"
      },
      "source": [
        "# RandomForest Regressor and memory bank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn5-NR3wFJzJ",
        "outputId": "d31ef43d-8714-453a-d9de-18c1dd65ae6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Collecting data samples\n",
        "def create_dataset(env, horizon, device=\"cpu\", disable_tqdm=False):\n",
        "    \"\"\"\n",
        "    Collects a dataset of states, actions, rewards, next states, and done flags by interacting with the environment.\n",
        "\n",
        "    Args:\n",
        "        env: The environment to interact with.\n",
        "        horizon: Number of steps to collect.\n",
        "        device: \"cpu\" or \"cuda\" to specify where tensors should be stored.\n",
        "        disable_tqdm: Disables tqdm progress bar if True.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of PyTorch tensors (S, A, R, S2, D).\n",
        "    \"\"\"\n",
        "    s, _ = env.reset()\n",
        "    S, A, R, S2, D = [], [], [], [], []\n",
        "\n",
        "    for _ in tqdm(range(horizon), disable=disable_tqdm):\n",
        "        a = env.action_space.sample()\n",
        "        s2, r, done, trunc, _ = env.step(a)\n",
        "\n",
        "        S.append(s)\n",
        "        A.append(a)\n",
        "        R.append(r)\n",
        "        S2.append(s2)\n",
        "        D.append(done)\n",
        "\n",
        "        if done or trunc:\n",
        "            s, _ = env.reset()\n",
        "        else:\n",
        "            s = s2\n",
        "\n",
        "    # Convert to PyTorch tensors and move to the specified device\n",
        "    S = torch.tensor(np.array(S), dtype=torch.float32, device=device)\n",
        "    A = torch.tensor(np.array(A).reshape((-1, 1)), dtype=torch.float32, device=device)\n",
        "    R = torch.tensor(np.array(R), dtype=torch.float32, device=device)\n",
        "    S2 = torch.tensor(np.array(S2), dtype=torch.float32, device=device)\n",
        "    D = torch.tensor(np.array(D), dtype=torch.bool, device=device)\n",
        "\n",
        "    return S, A, R, S2, D\n",
        "\n",
        "def save_dataset(dataset, path=None):\n",
        "    \"\"\"\n",
        "    Saves the dataset to a compressed NumPy file.\n",
        "\n",
        "    Args:\n",
        "        dataset: Tuple of tensors (S, A, R, S2, D).\n",
        "        path: File path to save the dataset. If None, uses a default naming scheme.\n",
        "    \"\"\"\n",
        "    if path is not None:\n",
        "        torch.save(dataset, path)\n",
        "    else:\n",
        "        n = len(dataset[0])\n",
        "        torch.save(dataset, f'data_{n}.pt')\n",
        "\n",
        "def load_dataset(path, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Loads a dataset saved as a PyTorch file.\n",
        "\n",
        "    Args:\n",
        "        path: File path of the dataset.\n",
        "        device: Device to load the dataset onto (\"cpu\" or \"cuda\").\n",
        "\n",
        "    Returns:\n",
        "        Dataset as a tuple of PyTorch tensors (S, A, R, S2, D).\n",
        "    \"\"\"\n",
        "    dataset = torch.load(path, map_location=device)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Check GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "env = TimeLimit(\n",
        "    env=HIVPatient(domain_randomization=False), max_episode_steps=200\n",
        ")\n",
        "horizon = int(1e5)\n",
        "#dataset = create_dataset(env, horizon, device=device)\n",
        "#save_dataset(dataset, path =  path + 'data_1M.npz')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qJK-4VTBHOcL"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path):\n",
        "    dataset = np.load(path)\n",
        "    return dataset\n",
        "dataset = load_dataset(path+ \"sample_bank.npz\")\n",
        "S, A, R, S2, D = dataset.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "87ekwJoYHuFs"
      },
      "outputs": [],
      "source": [
        "def rf_fqi(S, A, R, S2, D, iterations, nb_actions, gamma, disable_tqdm=False):\n",
        "    # Convert data to PyTorch tensors for GPU acceleration if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    S = torch.tensor(S, dtype=torch.float32, device=device)\n",
        "    A = torch.tensor(A, dtype=torch.float32, device=device)\n",
        "    R = torch.tensor(R, dtype=torch.float32, device=device)\n",
        "    S2 = torch.tensor(S2, dtype=torch.float32, device=device)\n",
        "    D = torch.tensor(D, dtype=torch.float32, device=device)\n",
        "\n",
        "    nb_samples = S.shape[0]\n",
        "    Qfunctions = []\n",
        "\n",
        "    # Combine S and A initially\n",
        "    SA = torch.cat((S, A), dim=1).cpu().numpy()\n",
        "\n",
        "    for iter in tqdm(range(iterations), disable=disable_tqdm):\n",
        "        if iter == 0:\n",
        "            value = R.clone().cpu().numpy()\n",
        "        else:\n",
        "            Q2 = torch.zeros((nb_samples, nb_actions), device=device)\n",
        "            for a2 in range(nb_actions):\n",
        "                A2 = torch.full((S2.shape[0], 1), a2, dtype=torch.float32, device=device)\n",
        "                S2A2 = torch.cat((S2, A2), dim=1).cpu().numpy()\n",
        "                Q2[:, a2] = torch.tensor(Qfunctions[-1].predict(S2A2), device=device)\n",
        "            max_Q2 = torch.max(Q2, dim=1).values\n",
        "            value = R + gamma * (1 - D) * max_Q2\n",
        "            value = value.cpu().numpy()\n",
        "\n",
        "        Q = RandomForestRegressor()\n",
        "        Q.fit(SA, value)\n",
        "        Qfunctions.append(Q)\n",
        "\n",
        "    return Qfunctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "h5zV4xDaH9K4"
      },
      "outputs": [],
      "source": [
        "gamma = .8\n",
        "nb_iter = 1\n",
        "nb_actions = 4\n",
        "Qfunctions = rf_fqi(S, A, R, S2, D, nb_iter, nb_actions, gamma)\n",
        "# Save the model\n",
        "with open(path + \"rfrg.pkl\", \"wb\") as f:\n",
        "    pickle.dump(Qfunctions[-1], f)\n",
        "\n",
        "# Load the model\n",
        "with open(path + \"rfrg.pkl\", \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IOekg0jzLGVP"
      },
      "outputs": [],
      "source": [
        "class ProjectAgent:\n",
        "    def __init__(self):\n",
        "        self.Q = None\n",
        "\n",
        "    def act(self, observation, use_random=False):\n",
        "        # We will use the Greedy action that maximizes the utility function\n",
        "        Qsa = []\n",
        "        # Looping over actions\n",
        "        for a in range(4):\n",
        "            sa = np.append(observation,a).reshape(1, -1)\n",
        "            Qsa.append(self.Q.predict(sa))\n",
        "        return np.argmax(Qsa)\n",
        "\n",
        "    def save(self, path):\n",
        "        # Save the model\n",
        "        pass\n",
        "\n",
        "    def load(self, path = path):\n",
        "        with open(path + \"lgb_regressor.pkl\", \"rb\") as f:\n",
        "            loaded_model = pickle.load(f)\n",
        "        self.Q = loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kURdSuBhLpdZ"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file = Path(\"score.txt\")\n",
        "    if not file.is_file():\n",
        "        seed_everything(seed=42)\n",
        "        # Initialization of the agent. Replace DummyAgent with your custom agent implementation.\n",
        "        agent = ProjectAgent()\n",
        "        agent.load()\n",
        "        # Evaluate agent and write score.\n",
        "        score_agent: float = evaluate_HIV(agent=agent, nb_episode=5)\n",
        "        score_agent_dr: float = evaluate_HIV_population(agent=agent, nb_episode=20)\n",
        "        print(f\"Score agent: {score_agent}\")\n",
        "        print(f\"Score agent with domain randomization: {score_agent_dr}\")\n",
        "        with open(file= path + \"score.txt\", mode=\"w\") as f:\n",
        "            f.write(f\"{score_agent}\\n{score_agent_dr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzgzW_As8qos"
      },
      "source": [
        "# DQN tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdx8Qtj6Ddp9"
      },
      "source": [
        "## ReplayBuffer (cf notebook 4 du cours, replaybuffer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7Pm85giuDdp9"
      },
      "outputs": [],
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity, device):\n",
        "        self.capacity = capacity\n",
        "        self.data = []\n",
        "        self.index = 0\n",
        "        self.device = device\n",
        "    def append(self, s, a, r, s_, d):\n",
        "        if len(self.data) < self.capacity:\n",
        "            self.data.append(None)\n",
        "        self.data[self.index] = (s, a, r, s_, d)\n",
        "        self.index = (self.index + 1) % self.capacity\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.data, batch_size)\n",
        "        return list(map(lambda x:torch.Tensor(np.array(x)).to(self.device), list(zip(*batch))))\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Ez1DpE5SGGj7"
      },
      "outputs": [],
      "source": [
        "def greedy_pick(model, state):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    with torch.no_grad():\n",
        "        Q = model(torch.Tensor(state).unsqueeze(0).to(device))\n",
        "        return torch.argmax(Q).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Hp8qZuqbnOc8"
      },
      "outputs": [],
      "source": [
        "# Environment setup with a time limit of 200 steps per episode\n",
        "env = TimeLimit(env=HIVPatient(domain_randomization=True), max_episode_steps=200)\n",
        "\n",
        "# Definition of the Deep Q-Network (DQN) model\n",
        "DQN = torch.nn.Sequential(\n",
        "            torch.nn.Linear(env.observation_space.shape[0], 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, env.action_space.n)\n",
        ")\n",
        "\n",
        "# ProjectAgent class to define agent logic\n",
        "class ProjectAgent:\n",
        "    def __init__(self):\n",
        "        # Configuration for the agent\n",
        "        self.nb_actions = env.action_space.n\n",
        "        self.learning_rate = 0.001\n",
        "        self.gamma = 0.98\n",
        "        self.buffer_size = 100000\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_max = 1.0\n",
        "        self.epsilon_decay_period = 20000\n",
        "        self.epsilon_delay_decay = 100\n",
        "        self.epsilon_delay = 20\n",
        "        self.epsilon_step = (self.epsilon_max - self.epsilon_min) / self.epsilon_decay_period\n",
        "        self.batch_size = 800\n",
        "        self.gradient_steps = 5\n",
        "        self.update_target_strategy = 'replace'\n",
        "        self.update_target_freq = 900\n",
        "        self.update_target_tau = 0.005\n",
        "        self.criterion = torch.nn.SmoothL1Loss()\n",
        "        self.fine_tuning = False\n",
        "\n",
        "        # Device setup (CUDA or CPU)\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        if not self.fine_tuning:\n",
        "            self.model = DQN.to(self.device)\n",
        "        self.target_model = deepcopy(self.model).to(self.device)\n",
        "        self.memory = ReplayBuffer(self.buffer_size, self.device)\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.optimizer2 = torch.optim.AdamW(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    def act(self, observation, use_random=False):\n",
        "        with torch.no_grad():  # Disable gradient computation for action selection\n",
        "            Q = self.model(torch.Tensor(observation).unsqueeze(0).to(self.device))\n",
        "            return torch.argmax(Q).item()\n",
        "\n",
        "    def save(self, path):\n",
        "        self.path = path + \"final_dqn.pt\"\n",
        "        torch.save(self.model.state_dict(), self.path)\n",
        "\n",
        "    def load(self):\n",
        "        self.path = path + \"final_dqn.pt\"\n",
        "        self.model = DQN.to(self.device)\n",
        "        self.model.load_state_dict(torch.load(self.path, map_location=self.device))\n",
        "        self.model.eval()\n",
        "\n",
        "    def train(self, max_episode):\n",
        "        previous_val = 0\n",
        "        episode_return = []\n",
        "        episode = 0\n",
        "        episode_cum_reward = 0\n",
        "        state, _ = env.reset()\n",
        "        epsilon = self.epsilon_max\n",
        "        step = 0\n",
        "        while episode < max_episode:\n",
        "            # Decay epsilon after a certain number of steps\n",
        "            if step > self.epsilon_delay:\n",
        "                epsilon = max(self.epsilon_min, epsilon - self.epsilon_step)\n",
        "\n",
        "            # Action selection (epsilon-greedy)\n",
        "            if np.random.rand() < epsilon:\n",
        "                action = env.action_space.sample()  # Exploration\n",
        "            else:\n",
        "                action = self.act(state)  # Exploitation\n",
        "\n",
        "            # Take action, observe result\n",
        "            next_state, reward, done, trunc, _ = env.step(action)\n",
        "            self.memory.append(state, action, reward, next_state, done)\n",
        "            episode_cum_reward += reward\n",
        "\n",
        "            # Train the model\n",
        "            for _ in range(self.gradient_steps):\n",
        "                if len(self.memory) > self.batch_size:\n",
        "                    X, A, R, Y, D = self.memory.sample(self.batch_size)\n",
        "                    QYmax = self.target_model(Y).max(1)[0].detach()\n",
        "                    update = torch.addcmul(R, 1 - D, QYmax, value=self.gamma)\n",
        "                    QXA = self.model(X).gather(1, A.to(torch.long).unsqueeze(1))\n",
        "                    loss = self.criterion(QXA, update.unsqueeze(1))\n",
        "                    self.optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "            # Update target model periodically\n",
        "            if self.update_target_strategy == 'replace':\n",
        "                if step % self.update_target_freq == 0:\n",
        "                    self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "            step += 1\n",
        "            if done or trunc:\n",
        "                episode += 1\n",
        "                val_score = evaluate_HIV(agent=self, nb_episode=1)\n",
        "\n",
        "                # Print training progress\n",
        "                print(f\"Episode {episode:3d} | \"\n",
        "                      f\"Epsilon {epsilon:6.2f} | \"\n",
        "                      f\"Batch Size {len(self.memory):5d} | \"\n",
        "                      f\"Episode Return {episode_cum_reward:.2e} | \"\n",
        "                      f\"Evaluation Score {val_score:.2e}\")\n",
        "                state, _ = env.reset()\n",
        "\n",
        "                # Save model if evaluation score improves\n",
        "                if val_score > previous_val:\n",
        "                    previous_val = val_score\n",
        "                    self.best_model = deepcopy(self.model).to(self.device)\n",
        "                    path = os.getcwd()\n",
        "                    self.save(path)\n",
        "                episode_return.append(episode_cum_reward)\n",
        "                episode_cum_reward = 0\n",
        "            else:\n",
        "                state = next_state\n",
        "\n",
        "        # Load the best model and save it\n",
        "        self.model.load_state_dict(self.best_model.state_dict())\n",
        "        path = os.getcwd()\n",
        "        self.save(path)\n",
        "        return episode_return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4O-Fr4snvyx",
        "outputId": "5776f0de-7cee-47ab-be05-4bb0a0c090e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Episode   1 | Epsilon   1.00 | Batch Size   200 | Episode Return 1.09e+07 | Evaluation Score 3.43e+06\n",
            "Episode   2 | Epsilon   0.99 | Batch Size   400 | Episode Return 7.95e+06 | Evaluation Score 3.43e+06\n",
            "Episode   3 | Epsilon   0.98 | Batch Size   600 | Episode Return 5.01e+06 | Evaluation Score 3.43e+06\n",
            "Episode   4 | Epsilon   0.97 | Batch Size   800 | Episode Return 6.58e+06 | Evaluation Score 3.65e+06\n",
            "Episode   5 | Epsilon   0.96 | Batch Size  1000 | Episode Return 1.11e+07 | Evaluation Score 3.38e+06\n",
            "Episode   6 | Epsilon   0.95 | Batch Size  1200 | Episode Return 5.71e+06 | Evaluation Score 6.50e+06\n",
            "Episode   7 | Epsilon   0.94 | Batch Size  1400 | Episode Return 6.77e+06 | Evaluation Score 6.34e+06\n",
            "Episode   8 | Epsilon   0.93 | Batch Size  1600 | Episode Return 1.01e+07 | Evaluation Score 4.65e+06\n",
            "Episode   9 | Epsilon   0.92 | Batch Size  1800 | Episode Return 1.38e+07 | Evaluation Score 6.75e+06\n",
            "Episode  10 | Epsilon   0.91 | Batch Size  2000 | Episode Return 9.20e+06 | Evaluation Score 6.86e+06\n",
            "Episode  11 | Epsilon   0.90 | Batch Size  2200 | Episode Return 1.11e+07 | Evaluation Score 5.12e+06\n",
            "Episode  12 | Epsilon   0.89 | Batch Size  2400 | Episode Return 7.44e+06 | Evaluation Score 4.46e+06\n",
            "Episode  13 | Epsilon   0.88 | Batch Size  2600 | Episode Return 8.18e+06 | Evaluation Score 4.68e+06\n",
            "Episode  14 | Epsilon   0.87 | Batch Size  2800 | Episode Return 9.16e+06 | Evaluation Score 4.74e+06\n",
            "Episode  15 | Epsilon   0.86 | Batch Size  3000 | Episode Return 1.02e+07 | Evaluation Score 9.71e+06\n",
            "Episode  16 | Epsilon   0.86 | Batch Size  3200 | Episode Return 1.06e+07 | Evaluation Score 7.13e+06\n",
            "Episode  17 | Epsilon   0.85 | Batch Size  3400 | Episode Return 1.30e+07 | Evaluation Score 4.26e+06\n",
            "Episode  18 | Epsilon   0.84 | Batch Size  3600 | Episode Return 1.16e+07 | Evaluation Score 7.09e+06\n",
            "Episode  19 | Epsilon   0.83 | Batch Size  3800 | Episode Return 1.09e+07 | Evaluation Score 5.63e+06\n",
            "Episode  20 | Epsilon   0.82 | Batch Size  4000 | Episode Return 1.23e+07 | Evaluation Score 6.37e+06\n",
            "Episode  21 | Epsilon   0.81 | Batch Size  4200 | Episode Return 8.23e+06 | Evaluation Score 7.10e+06\n",
            "Episode  22 | Epsilon   0.80 | Batch Size  4400 | Episode Return 1.54e+07 | Evaluation Score 8.12e+06\n",
            "Episode  23 | Epsilon   0.79 | Batch Size  4600 | Episode Return 1.51e+07 | Evaluation Score 8.21e+06\n",
            "Episode  24 | Epsilon   0.78 | Batch Size  4800 | Episode Return 1.97e+07 | Evaluation Score 9.08e+06\n",
            "Episode  25 | Epsilon   0.77 | Batch Size  5000 | Episode Return 1.26e+07 | Evaluation Score 7.46e+06\n",
            "Episode  26 | Epsilon   0.76 | Batch Size  5200 | Episode Return 1.17e+07 | Evaluation Score 6.69e+06\n",
            "Episode  27 | Epsilon   0.75 | Batch Size  5400 | Episode Return 1.05e+07 | Evaluation Score 7.43e+06\n",
            "Episode  28 | Epsilon   0.74 | Batch Size  5600 | Episode Return 1.71e+07 | Evaluation Score 6.74e+06\n",
            "Episode  29 | Epsilon   0.73 | Batch Size  5800 | Episode Return 1.83e+07 | Evaluation Score 8.06e+06\n",
            "Episode  30 | Epsilon   0.72 | Batch Size  6000 | Episode Return 1.04e+07 | Evaluation Score 7.88e+06\n",
            "Episode  31 | Epsilon   0.72 | Batch Size  6200 | Episode Return 1.31e+07 | Evaluation Score 8.16e+06\n",
            "Episode  32 | Epsilon   0.71 | Batch Size  6400 | Episode Return 3.34e+07 | Evaluation Score 7.16e+06\n",
            "Episode  33 | Epsilon   0.70 | Batch Size  6600 | Episode Return 1.01e+07 | Evaluation Score 9.17e+06\n",
            "Episode  34 | Epsilon   0.69 | Batch Size  6800 | Episode Return 1.86e+07 | Evaluation Score 9.16e+06\n",
            "Episode  35 | Epsilon   0.68 | Batch Size  7000 | Episode Return 1.62e+07 | Evaluation Score 8.14e+06\n",
            "Episode  36 | Epsilon   0.67 | Batch Size  7200 | Episode Return 1.74e+07 | Evaluation Score 6.90e+06\n",
            "Episode  37 | Epsilon   0.66 | Batch Size  7400 | Episode Return 1.05e+07 | Evaluation Score 8.39e+06\n",
            "Episode  38 | Epsilon   0.65 | Batch Size  7600 | Episode Return 9.80e+06 | Evaluation Score 9.74e+06\n",
            "Episode  39 | Epsilon   0.64 | Batch Size  7800 | Episode Return 1.54e+07 | Evaluation Score 8.59e+06\n",
            "Episode  40 | Epsilon   0.63 | Batch Size  8000 | Episode Return 2.02e+07 | Evaluation Score 7.74e+06\n",
            "Episode  41 | Epsilon   0.62 | Batch Size  8200 | Episode Return 1.23e+07 | Evaluation Score 7.71e+06\n",
            "Episode  42 | Epsilon   0.61 | Batch Size  8400 | Episode Return 1.38e+07 | Evaluation Score 7.76e+06\n",
            "Episode  43 | Epsilon   0.60 | Batch Size  8600 | Episode Return 2.10e+07 | Evaluation Score 6.46e+06\n",
            "Episode  44 | Epsilon   0.59 | Batch Size  8800 | Episode Return 2.21e+07 | Evaluation Score 5.98e+06\n",
            "Episode  45 | Epsilon   0.58 | Batch Size  9000 | Episode Return 2.01e+07 | Evaluation Score 7.77e+06\n",
            "Episode  46 | Epsilon   0.58 | Batch Size  9200 | Episode Return 2.16e+07 | Evaluation Score 9.93e+06\n",
            "Episode  47 | Epsilon   0.57 | Batch Size  9400 | Episode Return 3.52e+07 | Evaluation Score 8.27e+06\n",
            "Episode  48 | Epsilon   0.56 | Batch Size  9600 | Episode Return 2.59e+07 | Evaluation Score 8.06e+06\n",
            "Episode  49 | Epsilon   0.55 | Batch Size  9800 | Episode Return 3.42e+07 | Evaluation Score 7.24e+06\n",
            "Episode  50 | Epsilon   0.54 | Batch Size 10000 | Episode Return 4.52e+07 | Evaluation Score 7.79e+06\n",
            "Episode  51 | Epsilon   0.53 | Batch Size 10200 | Episode Return 2.02e+07 | Evaluation Score 6.57e+06\n",
            "Episode  52 | Epsilon   0.52 | Batch Size 10400 | Episode Return 2.50e+07 | Evaluation Score 8.33e+06\n",
            "Episode  53 | Epsilon   0.51 | Batch Size 10600 | Episode Return 9.11e+07 | Evaluation Score 8.91e+06\n",
            "Episode  54 | Epsilon   0.50 | Batch Size 10800 | Episode Return 1.88e+07 | Evaluation Score 7.57e+06\n",
            "Episode  55 | Epsilon   0.49 | Batch Size 11000 | Episode Return 3.23e+07 | Evaluation Score 7.35e+06\n",
            "Episode  56 | Epsilon   0.48 | Batch Size 11200 | Episode Return 2.40e+07 | Evaluation Score 6.84e+06\n",
            "Episode  57 | Epsilon   0.47 | Batch Size 11400 | Episode Return 4.21e+07 | Evaluation Score 9.44e+06\n",
            "Episode  58 | Epsilon   0.46 | Batch Size 11600 | Episode Return 4.30e+07 | Evaluation Score 8.78e+06\n",
            "Episode  59 | Epsilon   0.45 | Batch Size 11800 | Episode Return 1.97e+07 | Evaluation Score 8.30e+06\n",
            "Episode  60 | Epsilon   0.44 | Batch Size 12000 | Episode Return 3.86e+07 | Evaluation Score 7.76e+06\n",
            "Episode  61 | Epsilon   0.44 | Batch Size 12200 | Episode Return 3.04e+07 | Evaluation Score 8.63e+06\n",
            "Episode  62 | Epsilon   0.43 | Batch Size 12400 | Episode Return 2.75e+07 | Evaluation Score 9.92e+06\n",
            "Episode  63 | Epsilon   0.42 | Batch Size 12600 | Episode Return 5.95e+07 | Evaluation Score 9.39e+06\n",
            "Episode  64 | Epsilon   0.41 | Batch Size 12800 | Episode Return 6.11e+07 | Evaluation Score 8.27e+06\n",
            "Episode  65 | Epsilon   0.40 | Batch Size 13000 | Episode Return 3.20e+07 | Evaluation Score 2.71e+07\n",
            "Episode  66 | Epsilon   0.39 | Batch Size 13200 | Episode Return 6.39e+07 | Evaluation Score 9.39e+06\n",
            "Episode  67 | Epsilon   0.38 | Batch Size 13400 | Episode Return 5.97e+07 | Evaluation Score 9.09e+06\n",
            "Episode  68 | Epsilon   0.37 | Batch Size 13600 | Episode Return 1.00e+08 | Evaluation Score 2.00e+07\n",
            "Episode  69 | Epsilon   0.36 | Batch Size 13800 | Episode Return 9.96e+07 | Evaluation Score 1.59e+07\n",
            "Episode  70 | Epsilon   0.35 | Batch Size 14000 | Episode Return 5.86e+07 | Evaluation Score 1.06e+07\n",
            "Episode  71 | Epsilon   0.34 | Batch Size 14200 | Episode Return 5.08e+07 | Evaluation Score 2.12e+07\n",
            "Episode  72 | Epsilon   0.33 | Batch Size 14400 | Episode Return 1.34e+08 | Evaluation Score 9.34e+06\n",
            "Episode  73 | Epsilon   0.32 | Batch Size 14600 | Episode Return 1.83e+08 | Evaluation Score 9.55e+06\n",
            "Episode  74 | Epsilon   0.31 | Batch Size 14800 | Episode Return 6.72e+07 | Evaluation Score 1.53e+07\n",
            "Episode  75 | Epsilon   0.30 | Batch Size 15000 | Episode Return 1.59e+08 | Evaluation Score 9.34e+06\n",
            "Episode  76 | Epsilon   0.30 | Batch Size 15200 | Episode Return 3.82e+08 | Evaluation Score 1.49e+07\n",
            "Episode  77 | Epsilon   0.29 | Batch Size 15400 | Episode Return 6.04e+07 | Evaluation Score 1.49e+07\n",
            "Episode  78 | Epsilon   0.28 | Batch Size 15600 | Episode Return 1.07e+08 | Evaluation Score 1.34e+07\n",
            "Episode  79 | Epsilon   0.27 | Batch Size 15800 | Episode Return 9.58e+07 | Evaluation Score 1.49e+07\n",
            "Episode  80 | Epsilon   0.26 | Batch Size 16000 | Episode Return 4.34e+08 | Evaluation Score 7.70e+06\n",
            "Episode  81 | Epsilon   0.25 | Batch Size 16200 | Episode Return 5.02e+08 | Evaluation Score 1.72e+07\n",
            "Episode  82 | Epsilon   0.24 | Batch Size 16400 | Episode Return 1.29e+08 | Evaluation Score 1.81e+07\n",
            "Episode  83 | Epsilon   0.23 | Batch Size 16600 | Episode Return 5.65e+08 | Evaluation Score 1.93e+07\n",
            "Episode  84 | Epsilon   0.22 | Batch Size 16800 | Episode Return 1.18e+09 | Evaluation Score 1.49e+07\n",
            "Episode  85 | Epsilon   0.21 | Batch Size 17000 | Episode Return 7.72e+08 | Evaluation Score 8.97e+06\n",
            "Episode  86 | Epsilon   0.20 | Batch Size 17200 | Episode Return 3.46e+08 | Evaluation Score 9.90e+06\n",
            "Episode  87 | Epsilon   0.19 | Batch Size 17400 | Episode Return 1.92e+09 | Evaluation Score 1.96e+07\n",
            "Episode  88 | Epsilon   0.18 | Batch Size 17600 | Episode Return 2.36e+09 | Evaluation Score 2.00e+07\n",
            "Episode  89 | Epsilon   0.17 | Batch Size 17800 | Episode Return 2.31e+08 | Evaluation Score 2.73e+07\n",
            "Episode  90 | Epsilon   0.16 | Batch Size 18000 | Episode Return 9.06e+08 | Evaluation Score 1.27e+07\n",
            "Episode  91 | Epsilon   0.16 | Batch Size 18200 | Episode Return 5.13e+09 | Evaluation Score 9.88e+06\n",
            "Episode  92 | Epsilon   0.15 | Batch Size 18400 | Episode Return 4.71e+09 | Evaluation Score 1.46e+07\n",
            "Episode  93 | Epsilon   0.14 | Batch Size 18600 | Episode Return 3.66e+09 | Evaluation Score 9.41e+06\n",
            "Episode  94 | Epsilon   0.13 | Batch Size 18800 | Episode Return 7.35e+08 | Evaluation Score 9.56e+06\n",
            "Episode  95 | Epsilon   0.12 | Batch Size 19000 | Episode Return 1.19e+10 | Evaluation Score 1.64e+07\n",
            "Episode  96 | Epsilon   0.11 | Batch Size 19200 | Episode Return 5.50e+09 | Evaluation Score 1.64e+07\n",
            "Episode  97 | Epsilon   0.10 | Batch Size 19400 | Episode Return 5.91e+09 | Evaluation Score 1.86e+07\n",
            "Episode  98 | Epsilon   0.09 | Batch Size 19600 | Episode Return 6.12e+09 | Evaluation Score 1.91e+07\n",
            "Episode  99 | Epsilon   0.08 | Batch Size 19800 | Episode Return 2.14e+10 | Evaluation Score 1.50e+07\n",
            "Episode 100 | Epsilon   0.07 | Batch Size 20000 | Episode Return 4.45e+09 | Evaluation Score 1.61e+07\n",
            "Episode 101 | Epsilon   0.06 | Batch Size 20200 | Episode Return 1.79e+09 | Evaluation Score 1.75e+07\n",
            "Episode 102 | Epsilon   0.05 | Batch Size 20400 | Episode Return 1.56e+10 | Evaluation Score 1.95e+07\n",
            "Episode 103 | Epsilon   0.04 | Batch Size 20600 | Episode Return 4.06e+07 | Evaluation Score 1.19e+07\n",
            "Episode 104 | Epsilon   0.03 | Batch Size 20800 | Episode Return 2.01e+10 | Evaluation Score 1.68e+07\n",
            "Episode 105 | Epsilon   0.02 | Batch Size 21000 | Episode Return 1.10e+08 | Evaluation Score 1.88e+07\n",
            "Episode 106 | Epsilon   0.02 | Batch Size 21200 | Episode Return 1.01e+09 | Evaluation Score 1.38e+07\n",
            "Episode 107 | Epsilon   0.02 | Batch Size 21400 | Episode Return 1.95e+10 | Evaluation Score 1.77e+07\n",
            "Episode 108 | Epsilon   0.02 | Batch Size 21600 | Episode Return 2.17e+10 | Evaluation Score 1.64e+07\n",
            "Episode 109 | Epsilon   0.02 | Batch Size 21800 | Episode Return 3.28e+07 | Evaluation Score 1.88e+07\n",
            "Episode 110 | Epsilon   0.02 | Batch Size 22000 | Episode Return 1.82e+07 | Evaluation Score 1.84e+07\n",
            "Episode 111 | Epsilon   0.02 | Batch Size 22200 | Episode Return 2.54e+07 | Evaluation Score 9.28e+06\n",
            "Episode 112 | Epsilon   0.02 | Batch Size 22400 | Episode Return 7.28e+09 | Evaluation Score 1.84e+07\n",
            "Episode 113 | Epsilon   0.02 | Batch Size 22600 | Episode Return 1.34e+10 | Evaluation Score 2.07e+07\n",
            "Episode 114 | Epsilon   0.02 | Batch Size 22800 | Episode Return 1.93e+10 | Evaluation Score 1.85e+07\n",
            "Episode 115 | Epsilon   0.02 | Batch Size 23000 | Episode Return 1.59e+10 | Evaluation Score 1.19e+07\n",
            "Episode 116 | Epsilon   0.02 | Batch Size 23200 | Episode Return 2.55e+10 | Evaluation Score 2.00e+07\n",
            "Episode 117 | Epsilon   0.02 | Batch Size 23400 | Episode Return 6.13e+07 | Evaluation Score 2.46e+07\n",
            "Episode 118 | Epsilon   0.02 | Batch Size 23600 | Episode Return 2.62e+10 | Evaluation Score 1.43e+07\n",
            "Episode 119 | Epsilon   0.02 | Batch Size 23800 | Episode Return 1.55e+10 | Evaluation Score 8.00e+06\n",
            "Episode 120 | Epsilon   0.02 | Batch Size 24000 | Episode Return 2.58e+10 | Evaluation Score 1.07e+07\n",
            "Episode 121 | Epsilon   0.02 | Batch Size 24200 | Episode Return 1.23e+09 | Evaluation Score 2.03e+07\n",
            "Episode 122 | Epsilon   0.02 | Batch Size 24400 | Episode Return 1.41e+10 | Evaluation Score 2.14e+07\n",
            "Episode 123 | Epsilon   0.02 | Batch Size 24600 | Episode Return 2.23e+10 | Evaluation Score 2.73e+07\n",
            "Episode 124 | Epsilon   0.02 | Batch Size 24800 | Episode Return 2.75e+10 | Evaluation Score 2.84e+07\n",
            "Episode 125 | Epsilon   0.02 | Batch Size 25000 | Episode Return 1.93e+10 | Evaluation Score 3.20e+07\n",
            "Episode 126 | Epsilon   0.02 | Batch Size 25200 | Episode Return 8.30e+09 | Evaluation Score 2.07e+07\n",
            "Episode 127 | Epsilon   0.02 | Batch Size 25400 | Episode Return 1.65e+10 | Evaluation Score 1.06e+07\n",
            "Episode 128 | Epsilon   0.02 | Batch Size 25600 | Episode Return 1.72e+10 | Evaluation Score 2.56e+07\n",
            "Episode 129 | Epsilon   0.02 | Batch Size 25800 | Episode Return 8.14e+09 | Evaluation Score 3.26e+07\n",
            "Episode 130 | Epsilon   0.02 | Batch Size 26000 | Episode Return 2.68e+10 | Evaluation Score 2.59e+07\n",
            "Episode 131 | Epsilon   0.02 | Batch Size 26200 | Episode Return 6.31e+07 | Evaluation Score 3.35e+07\n",
            "Episode 132 | Epsilon   0.02 | Batch Size 26400 | Episode Return 3.02e+09 | Evaluation Score 2.80e+07\n",
            "Episode 133 | Epsilon   0.02 | Batch Size 26600 | Episode Return 2.48e+10 | Evaluation Score 4.12e+07\n",
            "Episode 134 | Epsilon   0.02 | Batch Size 26800 | Episode Return 2.85e+10 | Evaluation Score 3.86e+07\n",
            "Episode 135 | Epsilon   0.02 | Batch Size 27000 | Episode Return 1.49e+10 | Evaluation Score 2.56e+07\n",
            "Episode 136 | Epsilon   0.02 | Batch Size 27200 | Episode Return 9.31e+09 | Evaluation Score 2.56e+07\n",
            "Episode 137 | Epsilon   0.02 | Batch Size 27400 | Episode Return 2.93e+10 | Evaluation Score 2.56e+07\n",
            "Episode 138 | Epsilon   0.02 | Batch Size 27600 | Episode Return 1.69e+08 | Evaluation Score 2.74e+07\n",
            "Episode 139 | Epsilon   0.02 | Batch Size 27800 | Episode Return 1.16e+08 | Evaluation Score 3.27e+07\n",
            "Episode 140 | Epsilon   0.02 | Batch Size 28000 | Episode Return 2.04e+10 | Evaluation Score 7.82e+06\n",
            "Episode 141 | Epsilon   0.02 | Batch Size 28200 | Episode Return 6.38e+07 | Evaluation Score 3.90e+07\n",
            "Episode 142 | Epsilon   0.02 | Batch Size 28400 | Episode Return 3.21e+10 | Evaluation Score 2.56e+07\n",
            "Episode 143 | Epsilon   0.02 | Batch Size 28600 | Episode Return 1.98e+10 | Evaluation Score 3.86e+07\n",
            "Episode 144 | Epsilon   0.02 | Batch Size 28800 | Episode Return 3.17e+10 | Evaluation Score 3.63e+07\n",
            "Episode 145 | Epsilon   0.02 | Batch Size 29000 | Episode Return 3.07e+10 | Evaluation Score 3.79e+07\n",
            "Episode 146 | Epsilon   0.02 | Batch Size 29200 | Episode Return 2.50e+10 | Evaluation Score 2.31e+07\n",
            "Episode 147 | Epsilon   0.02 | Batch Size 29400 | Episode Return 2.83e+10 | Evaluation Score 2.79e+07\n",
            "Episode 148 | Epsilon   0.02 | Batch Size 29600 | Episode Return 1.93e+10 | Evaluation Score 1.53e+07\n",
            "Episode 149 | Epsilon   0.02 | Batch Size 29800 | Episode Return 2.18e+10 | Evaluation Score 7.48e+06\n",
            "Episode 150 | Epsilon   0.02 | Batch Size 30000 | Episode Return 2.70e+10 | Evaluation Score 5.09e+09\n",
            "Episode 151 | Epsilon   0.02 | Batch Size 30200 | Episode Return 2.22e+10 | Evaluation Score 4.19e+09\n",
            "Episode 152 | Epsilon   0.02 | Batch Size 30400 | Episode Return 2.14e+10 | Evaluation Score 1.69e+09\n",
            "Episode 153 | Epsilon   0.02 | Batch Size 30600 | Episode Return 3.09e+10 | Evaluation Score 1.51e+09\n",
            "Episode 154 | Epsilon   0.02 | Batch Size 30800 | Episode Return 2.50e+10 | Evaluation Score 3.01e+09\n",
            "Episode 155 | Epsilon   0.02 | Batch Size 31000 | Episode Return 2.21e+10 | Evaluation Score 1.78e+09\n",
            "Episode 156 | Epsilon   0.02 | Batch Size 31200 | Episode Return 2.66e+10 | Evaluation Score 1.89e+09\n",
            "Episode 157 | Epsilon   0.02 | Batch Size 31400 | Episode Return 2.34e+10 | Evaluation Score 1.88e+09\n",
            "Episode 158 | Epsilon   0.02 | Batch Size 31600 | Episode Return 1.49e+10 | Evaluation Score 2.45e+09\n",
            "Episode 159 | Epsilon   0.02 | Batch Size 31800 | Episode Return 2.67e+10 | Evaluation Score 2.40e+09\n",
            "Episode 160 | Epsilon   0.02 | Batch Size 32000 | Episode Return 2.15e+10 | Evaluation Score 2.32e+09\n",
            "Episode 161 | Epsilon   0.02 | Batch Size 32200 | Episode Return 1.47e+10 | Evaluation Score 1.90e+10\n",
            "Episode 162 | Epsilon   0.02 | Batch Size 32400 | Episode Return 1.40e+10 | Evaluation Score 2.65e+09\n",
            "Episode 163 | Epsilon   0.02 | Batch Size 32600 | Episode Return 2.00e+09 | Evaluation Score 1.14e+10\n",
            "Episode 164 | Epsilon   0.02 | Batch Size 32800 | Episode Return 2.29e+10 | Evaluation Score 2.93e+09\n",
            "Episode 165 | Epsilon   0.02 | Batch Size 33000 | Episode Return 1.84e+10 | Evaluation Score 2.14e+10\n",
            "Episode 166 | Epsilon   0.02 | Batch Size 33200 | Episode Return 2.79e+10 | Evaluation Score 1.44e+10\n",
            "Episode 167 | Epsilon   0.02 | Batch Size 33400 | Episode Return 3.00e+09 | Evaluation Score 2.61e+09\n",
            "Episode 168 | Epsilon   0.02 | Batch Size 33600 | Episode Return 2.99e+10 | Evaluation Score 2.43e+07\n",
            "Episode 169 | Epsilon   0.02 | Batch Size 33800 | Episode Return 2.06e+10 | Evaluation Score 2.97e+10\n",
            "Episode 170 | Epsilon   0.02 | Batch Size 34000 | Episode Return 7.69e+09 | Evaluation Score 1.47e+10\n",
            "Episode 171 | Epsilon   0.02 | Batch Size 34200 | Episode Return 2.45e+10 | Evaluation Score 8.77e+09\n",
            "Episode 172 | Epsilon   0.02 | Batch Size 34400 | Episode Return 1.91e+10 | Evaluation Score 9.59e+09\n",
            "Episode 173 | Epsilon   0.02 | Batch Size 34600 | Episode Return 2.53e+10 | Evaluation Score 1.04e+10\n",
            "Episode 174 | Epsilon   0.02 | Batch Size 34800 | Episode Return 1.96e+10 | Evaluation Score 1.20e+08\n",
            "Episode 175 | Epsilon   0.02 | Batch Size 35000 | Episode Return 3.44e+10 | Evaluation Score 2.34e+10\n",
            "Episode 176 | Epsilon   0.02 | Batch Size 35200 | Episode Return 1.86e+10 | Evaluation Score 3.00e+10\n",
            "Episode 177 | Epsilon   0.02 | Batch Size 35400 | Episode Return 2.25e+10 | Evaluation Score 5.08e+07\n",
            "Episode 178 | Epsilon   0.02 | Batch Size 35600 | Episode Return 1.74e+10 | Evaluation Score 5.01e+07\n",
            "Episode 179 | Epsilon   0.02 | Batch Size 35800 | Episode Return 2.27e+10 | Evaluation Score 1.71e+08\n",
            "Episode 180 | Epsilon   0.02 | Batch Size 36000 | Episode Return 2.69e+10 | Evaluation Score 1.01e+08\n",
            "Episode 181 | Epsilon   0.02 | Batch Size 36200 | Episode Return 2.50e+10 | Evaluation Score 3.03e+09\n",
            "Episode 182 | Epsilon   0.02 | Batch Size 36400 | Episode Return 2.76e+10 | Evaluation Score 9.67e+09\n",
            "Episode 183 | Epsilon   0.02 | Batch Size 36600 | Episode Return 2.72e+10 | Evaluation Score 9.94e+09\n",
            "Episode 184 | Epsilon   0.02 | Batch Size 36800 | Episode Return 2.99e+10 | Evaluation Score 7.87e+09\n",
            "Episode 185 | Epsilon   0.02 | Batch Size 37000 | Episode Return 1.40e+10 | Evaluation Score 2.53e+07\n",
            "Episode 186 | Epsilon   0.02 | Batch Size 37200 | Episode Return 3.00e+10 | Evaluation Score 6.46e+09\n",
            "Episode 187 | Epsilon   0.02 | Batch Size 37400 | Episode Return 2.41e+10 | Evaluation Score 2.82e+08\n",
            "Episode 188 | Epsilon   0.02 | Batch Size 37600 | Episode Return 1.99e+10 | Evaluation Score 7.97e+08\n",
            "Episode 189 | Epsilon   0.02 | Batch Size 37800 | Episode Return 3.42e+10 | Evaluation Score 1.14e+10\n",
            "Episode 190 | Epsilon   0.02 | Batch Size 38000 | Episode Return 2.19e+10 | Evaluation Score 1.22e+10\n",
            "Episode 191 | Epsilon   0.02 | Batch Size 38200 | Episode Return 2.41e+10 | Evaluation Score 1.19e+09\n",
            "Episode 192 | Epsilon   0.02 | Batch Size 38400 | Episode Return 2.49e+10 | Evaluation Score 1.13e+10\n",
            "Episode 193 | Epsilon   0.02 | Batch Size 38600 | Episode Return 2.99e+10 | Evaluation Score 1.17e+09\n",
            "Episode 194 | Epsilon   0.02 | Batch Size 38800 | Episode Return 1.61e+10 | Evaluation Score 1.64e+08\n",
            "Episode 195 | Epsilon   0.02 | Batch Size 39000 | Episode Return 2.64e+10 | Evaluation Score 2.99e+09\n",
            "Episode 196 | Epsilon   0.02 | Batch Size 39200 | Episode Return 9.17e+08 | Evaluation Score 2.93e+10\n",
            "Episode 197 | Epsilon   0.02 | Batch Size 39400 | Episode Return 2.56e+10 | Evaluation Score 2.27e+08\n",
            "Episode 198 | Epsilon   0.02 | Batch Size 39600 | Episode Return 3.15e+10 | Evaluation Score 1.31e+09\n",
            "Episode 199 | Epsilon   0.02 | Batch Size 39800 | Episode Return 2.04e+10 | Evaluation Score 3.98e+07\n",
            "Episode 200 | Epsilon   0.02 | Batch Size 40000 | Episode Return 1.86e+10 | Evaluation Score 3.40e+07\n",
            "Episode 201 | Epsilon   0.02 | Batch Size 40200 | Episode Return 2.90e+10 | Evaluation Score 8.97e+09\n",
            "Episode 202 | Epsilon   0.02 | Batch Size 40400 | Episode Return 1.92e+10 | Evaluation Score 3.44e+07\n",
            "Episode 203 | Epsilon   0.02 | Batch Size 40600 | Episode Return 2.64e+10 | Evaluation Score 3.73e+09\n",
            "Episode 204 | Epsilon   0.02 | Batch Size 40800 | Episode Return 3.26e+10 | Evaluation Score 8.76e+06\n",
            "Episode 205 | Epsilon   0.02 | Batch Size 41000 | Episode Return 2.28e+10 | Evaluation Score 1.83e+10\n",
            "Episode 206 | Epsilon   0.02 | Batch Size 41200 | Episode Return 2.04e+10 | Evaluation Score 1.78e+10\n",
            "Episode 207 | Epsilon   0.02 | Batch Size 41400 | Episode Return 2.46e+10 | Evaluation Score 1.64e+10\n",
            "Episode 208 | Epsilon   0.02 | Batch Size 41600 | Episode Return 7.53e+09 | Evaluation Score 2.84e+10\n",
            "Episode 209 | Epsilon   0.02 | Batch Size 41800 | Episode Return 2.27e+10 | Evaluation Score 2.26e+08\n",
            "Episode 210 | Epsilon   0.02 | Batch Size 42000 | Episode Return 1.32e+10 | Evaluation Score 1.23e+10\n",
            "Episode 211 | Epsilon   0.02 | Batch Size 42200 | Episode Return 2.88e+10 | Evaluation Score 3.10e+07\n",
            "Episode 212 | Epsilon   0.02 | Batch Size 42400 | Episode Return 2.33e+10 | Evaluation Score 2.22e+07\n",
            "Episode 213 | Epsilon   0.02 | Batch Size 42600 | Episode Return 1.90e+10 | Evaluation Score 5.25e+09\n",
            "Episode 214 | Epsilon   0.02 | Batch Size 42800 | Episode Return 2.14e+10 | Evaluation Score 9.41e+09\n",
            "Episode 215 | Epsilon   0.02 | Batch Size 43000 | Episode Return 2.04e+10 | Evaluation Score 1.38e+09\n",
            "Episode 216 | Epsilon   0.02 | Batch Size 43200 | Episode Return 2.75e+10 | Evaluation Score 1.26e+10\n",
            "Episode 217 | Epsilon   0.02 | Batch Size 43400 | Episode Return 1.51e+08 | Evaluation Score 1.13e+10\n",
            "Episode 218 | Epsilon   0.02 | Batch Size 43600 | Episode Return 2.83e+10 | Evaluation Score 4.06e+09\n",
            "Episode 219 | Epsilon   0.02 | Batch Size 43800 | Episode Return 3.04e+10 | Evaluation Score 9.15e+09\n",
            "Episode 220 | Epsilon   0.02 | Batch Size 44000 | Episode Return 2.80e+10 | Evaluation Score 6.28e+09\n",
            "Episode 221 | Epsilon   0.02 | Batch Size 44200 | Episode Return 2.71e+10 | Evaluation Score 1.55e+10\n",
            "Episode 222 | Epsilon   0.02 | Batch Size 44400 | Episode Return 3.15e+10 | Evaluation Score 5.95e+07\n",
            "Episode 223 | Epsilon   0.02 | Batch Size 44600 | Episode Return 2.25e+10 | Evaluation Score 1.75e+10\n",
            "Episode 224 | Epsilon   0.02 | Batch Size 44800 | Episode Return 2.60e+10 | Evaluation Score 1.90e+10\n",
            "Episode 225 | Epsilon   0.02 | Batch Size 45000 | Episode Return 2.07e+10 | Evaluation Score 1.54e+10\n",
            "Episode 226 | Epsilon   0.02 | Batch Size 45200 | Episode Return 3.24e+10 | Evaluation Score 2.09e+08\n",
            "Episode 227 | Epsilon   0.02 | Batch Size 45400 | Episode Return 1.51e+10 | Evaluation Score 1.05e+10\n",
            "Episode 228 | Epsilon   0.02 | Batch Size 45600 | Episode Return 9.33e+09 | Evaluation Score 1.20e+08\n",
            "Episode 229 | Epsilon   0.02 | Batch Size 45800 | Episode Return 1.85e+10 | Evaluation Score 4.29e+07\n",
            "Episode 230 | Epsilon   0.02 | Batch Size 46000 | Episode Return 2.00e+10 | Evaluation Score 3.57e+09\n",
            "Episode 231 | Epsilon   0.02 | Batch Size 46200 | Episode Return 1.98e+09 | Evaluation Score 3.42e+09\n",
            "Episode 232 | Epsilon   0.02 | Batch Size 46400 | Episode Return 1.20e+09 | Evaluation Score 1.44e+10\n",
            "Episode 233 | Epsilon   0.02 | Batch Size 46600 | Episode Return 1.85e+10 | Evaluation Score 5.64e+07\n",
            "Episode 234 | Epsilon   0.02 | Batch Size 46800 | Episode Return 7.08e+07 | Evaluation Score 6.41e+07\n",
            "Episode 235 | Epsilon   0.02 | Batch Size 47000 | Episode Return 1.88e+10 | Evaluation Score 1.90e+07\n",
            "Episode 236 | Epsilon   0.02 | Batch Size 47200 | Episode Return 1.74e+10 | Evaluation Score 2.13e+07\n",
            "Episode 237 | Epsilon   0.02 | Batch Size 47400 | Episode Return 2.14e+10 | Evaluation Score 5.13e+07\n",
            "Episode 238 | Epsilon   0.02 | Batch Size 47600 | Episode Return 1.62e+09 | Evaluation Score 7.58e+07\n",
            "Episode 239 | Epsilon   0.02 | Batch Size 47800 | Episode Return 1.55e+10 | Evaluation Score 2.38e+07\n",
            "Episode 240 | Epsilon   0.02 | Batch Size 48000 | Episode Return 2.60e+10 | Evaluation Score 1.47e+07\n",
            "Episode 241 | Epsilon   0.02 | Batch Size 48200 | Episode Return 4.89e+09 | Evaluation Score 2.40e+07\n",
            "Episode 242 | Epsilon   0.02 | Batch Size 48400 | Episode Return 1.24e+10 | Evaluation Score 1.47e+07\n",
            "Episode 243 | Epsilon   0.02 | Batch Size 48600 | Episode Return 1.63e+10 | Evaluation Score 6.89e+07\n",
            "Episode 244 | Epsilon   0.02 | Batch Size 48800 | Episode Return 1.35e+10 | Evaluation Score 2.66e+07\n",
            "Episode 245 | Epsilon   0.02 | Batch Size 49000 | Episode Return 1.12e+10 | Evaluation Score 1.90e+07\n",
            "Episode 246 | Epsilon   0.02 | Batch Size 49200 | Episode Return 9.56e+09 | Evaluation Score 2.04e+07\n",
            "Episode 247 | Epsilon   0.02 | Batch Size 49400 | Episode Return 2.88e+10 | Evaluation Score 1.16e+07\n",
            "Episode 248 | Epsilon   0.02 | Batch Size 49600 | Episode Return 2.63e+10 | Evaluation Score 1.19e+07\n",
            "Episode 249 | Epsilon   0.02 | Batch Size 49800 | Episode Return 5.14e+07 | Evaluation Score 1.70e+07\n",
            "Episode 250 | Epsilon   0.02 | Batch Size 50000 | Episode Return 2.41e+10 | Evaluation Score 1.19e+07\n",
            "Episode 251 | Epsilon   0.02 | Batch Size 50200 | Episode Return 2.02e+10 | Evaluation Score 2.78e+07\n",
            "Episode 252 | Epsilon   0.02 | Batch Size 50400 | Episode Return 1.33e+10 | Evaluation Score 8.61e+06\n",
            "Episode 253 | Epsilon   0.02 | Batch Size 50600 | Episode Return 5.94e+07 | Evaluation Score 2.07e+07\n",
            "Episode 254 | Epsilon   0.02 | Batch Size 50800 | Episode Return 5.42e+07 | Evaluation Score 1.74e+07\n",
            "Episode 255 | Epsilon   0.02 | Batch Size 51000 | Episode Return 2.15e+09 | Evaluation Score 1.57e+07\n",
            "Episode 256 | Epsilon   0.02 | Batch Size 51200 | Episode Return 7.81e+07 | Evaluation Score 3.71e+07\n",
            "Episode 257 | Epsilon   0.02 | Batch Size 51400 | Episode Return 1.55e+10 | Evaluation Score 1.69e+07\n",
            "Episode 258 | Epsilon   0.02 | Batch Size 51600 | Episode Return 7.85e+09 | Evaluation Score 1.20e+07\n",
            "Episode 259 | Epsilon   0.02 | Batch Size 51800 | Episode Return 3.24e+07 | Evaluation Score 1.84e+07\n",
            "Episode 260 | Epsilon   0.02 | Batch Size 52000 | Episode Return 7.44e+07 | Evaluation Score 2.75e+07\n",
            "Episode 261 | Epsilon   0.02 | Batch Size 52200 | Episode Return 2.29e+07 | Evaluation Score 7.04e+07\n",
            "Episode 262 | Epsilon   0.02 | Batch Size 52400 | Episode Return 1.46e+07 | Evaluation Score 3.00e+07\n",
            "Episode 263 | Epsilon   0.02 | Batch Size 52600 | Episode Return 1.45e+10 | Evaluation Score 4.00e+07\n",
            "Episode 264 | Epsilon   0.02 | Batch Size 52800 | Episode Return 3.58e+07 | Evaluation Score 1.13e+07\n",
            "Episode 265 | Epsilon   0.02 | Batch Size 53000 | Episode Return 4.08e+09 | Evaluation Score 1.42e+07\n",
            "Episode 266 | Epsilon   0.02 | Batch Size 53200 | Episode Return 1.60e+10 | Evaluation Score 1.13e+07\n",
            "Episode 267 | Epsilon   0.02 | Batch Size 53400 | Episode Return 2.37e+10 | Evaluation Score 3.57e+07\n",
            "Episode 268 | Epsilon   0.02 | Batch Size 53600 | Episode Return 2.37e+10 | Evaluation Score 2.98e+07\n",
            "Episode 269 | Epsilon   0.02 | Batch Size 53800 | Episode Return 1.79e+07 | Evaluation Score 1.39e+07\n",
            "Episode 270 | Epsilon   0.02 | Batch Size 54000 | Episode Return 1.02e+08 | Evaluation Score 1.08e+07\n",
            "Episode 271 | Epsilon   0.02 | Batch Size 54200 | Episode Return 4.35e+07 | Evaluation Score 4.85e+07\n",
            "Episode 272 | Epsilon   0.02 | Batch Size 54400 | Episode Return 3.49e+07 | Evaluation Score 3.17e+07\n",
            "Episode 273 | Epsilon   0.02 | Batch Size 54600 | Episode Return 1.51e+08 | Evaluation Score 4.78e+07\n",
            "Episode 274 | Epsilon   0.02 | Batch Size 54800 | Episode Return 3.57e+07 | Evaluation Score 1.13e+07\n",
            "Episode 275 | Epsilon   0.02 | Batch Size 55000 | Episode Return 2.84e+07 | Evaluation Score 3.23e+07\n",
            "Episode 276 | Epsilon   0.02 | Batch Size 55200 | Episode Return 4.05e+07 | Evaluation Score 3.84e+07\n",
            "Episode 277 | Epsilon   0.02 | Batch Size 55400 | Episode Return 4.24e+07 | Evaluation Score 2.96e+07\n",
            "Episode 278 | Epsilon   0.02 | Batch Size 55600 | Episode Return 3.83e+07 | Evaluation Score 2.96e+07\n",
            "Episode 279 | Epsilon   0.02 | Batch Size 55800 | Episode Return 2.22e+07 | Evaluation Score 2.06e+07\n",
            "Episode 280 | Epsilon   0.02 | Batch Size 56000 | Episode Return 3.85e+07 | Evaluation Score 1.77e+07\n",
            "Episode 281 | Epsilon   0.02 | Batch Size 56200 | Episode Return 1.88e+07 | Evaluation Score 2.23e+07\n",
            "Episode 282 | Epsilon   0.02 | Batch Size 56400 | Episode Return 1.68e+07 | Evaluation Score 2.24e+07\n",
            "Episode 283 | Epsilon   0.02 | Batch Size 56600 | Episode Return 2.07e+07 | Evaluation Score 2.73e+07\n",
            "Episode 284 | Epsilon   0.02 | Batch Size 56800 | Episode Return 3.32e+07 | Evaluation Score 1.71e+07\n",
            "Episode 285 | Epsilon   0.02 | Batch Size 57000 | Episode Return 1.92e+07 | Evaluation Score 9.03e+06\n",
            "Episode 286 | Epsilon   0.02 | Batch Size 57200 | Episode Return 2.12e+07 | Evaluation Score 9.35e+06\n",
            "Episode 287 | Epsilon   0.02 | Batch Size 57400 | Episode Return 2.12e+07 | Evaluation Score 1.90e+07\n",
            "Episode 288 | Epsilon   0.02 | Batch Size 57600 | Episode Return 2.10e+07 | Evaluation Score 2.18e+07\n",
            "Episode 289 | Epsilon   0.02 | Batch Size 57800 | Episode Return 1.91e+07 | Evaluation Score 2.34e+07\n",
            "Episode 290 | Epsilon   0.02 | Batch Size 58000 | Episode Return 2.19e+07 | Evaluation Score 2.26e+07\n",
            "Episode 291 | Epsilon   0.02 | Batch Size 58200 | Episode Return 1.52e+07 | Evaluation Score 1.92e+07\n",
            "Episode 292 | Epsilon   0.02 | Batch Size 58400 | Episode Return 2.17e+07 | Evaluation Score 1.82e+07\n",
            "Episode 293 | Epsilon   0.02 | Batch Size 58600 | Episode Return 1.70e+07 | Evaluation Score 1.79e+07\n",
            "Episode 294 | Epsilon   0.02 | Batch Size 58800 | Episode Return 1.68e+07 | Evaluation Score 8.67e+06\n",
            "Episode 295 | Epsilon   0.02 | Batch Size 59000 | Episode Return 1.97e+07 | Evaluation Score 1.20e+07\n",
            "Episode 296 | Epsilon   0.02 | Batch Size 59200 | Episode Return 2.54e+07 | Evaluation Score 1.35e+07\n",
            "Episode 297 | Epsilon   0.02 | Batch Size 59400 | Episode Return 2.45e+07 | Evaluation Score 1.95e+07\n",
            "Episode 298 | Epsilon   0.02 | Batch Size 59600 | Episode Return 1.94e+07 | Evaluation Score 2.12e+07\n",
            "Episode 299 | Epsilon   0.02 | Batch Size 59800 | Episode Return 1.75e+07 | Evaluation Score 2.03e+07\n",
            "Episode 300 | Epsilon   0.02 | Batch Size 60000 | Episode Return 1.92e+07 | Evaluation Score 2.15e+07\n",
            "Episode 301 | Epsilon   0.02 | Batch Size 60200 | Episode Return 2.71e+07 | Evaluation Score 9.88e+06\n",
            "Episode 302 | Epsilon   0.02 | Batch Size 60400 | Episode Return 2.81e+07 | Evaluation Score 1.07e+07\n",
            "Episode 303 | Epsilon   0.02 | Batch Size 60600 | Episode Return 1.86e+07 | Evaluation Score 9.23e+06\n",
            "Episode 304 | Epsilon   0.02 | Batch Size 60800 | Episode Return 2.25e+07 | Evaluation Score 1.01e+07\n",
            "Episode 305 | Epsilon   0.02 | Batch Size 61000 | Episode Return 1.60e+07 | Evaluation Score 6.43e+06\n",
            "Episode 306 | Epsilon   0.02 | Batch Size 61200 | Episode Return 1.15e+07 | Evaluation Score 1.82e+07\n",
            "Episode 307 | Epsilon   0.02 | Batch Size 61400 | Episode Return 2.05e+07 | Evaluation Score 1.02e+07\n",
            "Episode 308 | Epsilon   0.02 | Batch Size 61600 | Episode Return 1.83e+07 | Evaluation Score 1.55e+07\n",
            "Episode 309 | Epsilon   0.02 | Batch Size 61800 | Episode Return 1.83e+07 | Evaluation Score 9.72e+06\n",
            "Episode 310 | Epsilon   0.02 | Batch Size 62000 | Episode Return 2.77e+07 | Evaluation Score 1.03e+07\n",
            "Episode 311 | Epsilon   0.02 | Batch Size 62200 | Episode Return 3.03e+07 | Evaluation Score 9.36e+06\n",
            "Episode 312 | Epsilon   0.02 | Batch Size 62400 | Episode Return 1.86e+07 | Evaluation Score 1.08e+07\n",
            "Episode 313 | Epsilon   0.02 | Batch Size 62600 | Episode Return 1.96e+07 | Evaluation Score 9.64e+06\n",
            "Episode 314 | Epsilon   0.02 | Batch Size 62800 | Episode Return 2.04e+07 | Evaluation Score 1.06e+07\n",
            "Episode 315 | Epsilon   0.02 | Batch Size 63000 | Episode Return 8.72e+06 | Evaluation Score 1.42e+07\n",
            "Episode 316 | Epsilon   0.02 | Batch Size 63200 | Episode Return 1.60e+07 | Evaluation Score 1.09e+07\n",
            "Episode 317 | Epsilon   0.02 | Batch Size 63400 | Episode Return 1.30e+07 | Evaluation Score 7.88e+06\n",
            "Episode 318 | Epsilon   0.02 | Batch Size 63600 | Episode Return 9.84e+06 | Evaluation Score 8.47e+06\n",
            "Episode 319 | Epsilon   0.02 | Batch Size 63800 | Episode Return 6.19e+06 | Evaluation Score 1.37e+07\n",
            "Episode 320 | Epsilon   0.02 | Batch Size 64000 | Episode Return 1.50e+07 | Evaluation Score 1.28e+07\n",
            "Episode 321 | Epsilon   0.02 | Batch Size 64200 | Episode Return 1.84e+07 | Evaluation Score 1.38e+07\n",
            "Episode 322 | Epsilon   0.02 | Batch Size 64400 | Episode Return 1.67e+07 | Evaluation Score 1.20e+07\n",
            "Episode 323 | Epsilon   0.02 | Batch Size 64600 | Episode Return 2.33e+07 | Evaluation Score 7.94e+06\n",
            "Episode 324 | Epsilon   0.02 | Batch Size 64800 | Episode Return 1.91e+07 | Evaluation Score 1.72e+07\n",
            "Episode 325 | Epsilon   0.02 | Batch Size 65000 | Episode Return 1.56e+07 | Evaluation Score 1.07e+07\n",
            "Episode 326 | Epsilon   0.02 | Batch Size 65200 | Episode Return 2.25e+07 | Evaluation Score 8.01e+06\n",
            "Episode 327 | Epsilon   0.02 | Batch Size 65400 | Episode Return 2.08e+07 | Evaluation Score 9.60e+06\n",
            "Episode 328 | Epsilon   0.02 | Batch Size 65600 | Episode Return 1.54e+07 | Evaluation Score 1.09e+07\n",
            "Episode 329 | Epsilon   0.02 | Batch Size 65800 | Episode Return 5.65e+06 | Evaluation Score 1.20e+07\n",
            "Episode 330 | Epsilon   0.02 | Batch Size 66000 | Episode Return 2.36e+07 | Evaluation Score 1.04e+07\n",
            "Episode 331 | Epsilon   0.02 | Batch Size 66200 | Episode Return 1.75e+07 | Evaluation Score 1.84e+07\n",
            "Episode 332 | Epsilon   0.02 | Batch Size 66400 | Episode Return 2.31e+07 | Evaluation Score 1.84e+07\n",
            "Episode 333 | Epsilon   0.02 | Batch Size 66600 | Episode Return 1.68e+07 | Evaluation Score 1.67e+07\n",
            "Episode 334 | Epsilon   0.02 | Batch Size 66800 | Episode Return 2.68e+07 | Evaluation Score 2.74e+07\n",
            "Episode 335 | Epsilon   0.02 | Batch Size 67000 | Episode Return 2.81e+07 | Evaluation Score 3.15e+07\n",
            "Episode 336 | Epsilon   0.02 | Batch Size 67200 | Episode Return 1.19e+07 | Evaluation Score 2.78e+07\n",
            "Episode 337 | Epsilon   0.02 | Batch Size 67400 | Episode Return 1.81e+07 | Evaluation Score 3.07e+07\n",
            "Episode 338 | Epsilon   0.02 | Batch Size 67600 | Episode Return 2.75e+07 | Evaluation Score 3.21e+07\n",
            "Episode 339 | Epsilon   0.02 | Batch Size 67800 | Episode Return 3.10e+07 | Evaluation Score 2.44e+07\n",
            "Episode 340 | Epsilon   0.02 | Batch Size 68000 | Episode Return 2.14e+07 | Evaluation Score 2.82e+07\n",
            "Episode 341 | Epsilon   0.02 | Batch Size 68200 | Episode Return 1.72e+07 | Evaluation Score 3.01e+07\n",
            "Episode 342 | Epsilon   0.02 | Batch Size 68400 | Episode Return 2.16e+07 | Evaluation Score 1.18e+07\n",
            "Episode 343 | Epsilon   0.02 | Batch Size 68600 | Episode Return 6.37e+06 | Evaluation Score 2.70e+07\n",
            "Episode 344 | Epsilon   0.02 | Batch Size 68800 | Episode Return 2.38e+07 | Evaluation Score 2.58e+07\n",
            "Episode 345 | Epsilon   0.02 | Batch Size 69000 | Episode Return 1.37e+07 | Evaluation Score 1.75e+07\n",
            "Episode 346 | Epsilon   0.02 | Batch Size 69200 | Episode Return 2.53e+07 | Evaluation Score 2.51e+07\n",
            "Episode 347 | Epsilon   0.02 | Batch Size 69400 | Episode Return 1.05e+07 | Evaluation Score 2.97e+07\n",
            "Episode 348 | Epsilon   0.02 | Batch Size 69600 | Episode Return 2.70e+07 | Evaluation Score 3.07e+07\n",
            "Episode 349 | Epsilon   0.02 | Batch Size 69800 | Episode Return 2.22e+07 | Evaluation Score 2.16e+07\n",
            "Episode 350 | Epsilon   0.02 | Batch Size 70000 | Episode Return 2.17e+07 | Evaluation Score 2.08e+07\n",
            "Episode 351 | Epsilon   0.02 | Batch Size 70200 | Episode Return 8.92e+06 | Evaluation Score 2.98e+07\n",
            "Episode 352 | Epsilon   0.02 | Batch Size 70400 | Episode Return 9.81e+06 | Evaluation Score 2.81e+07\n",
            "Episode 353 | Epsilon   0.02 | Batch Size 70600 | Episode Return 1.96e+07 | Evaluation Score 3.08e+07\n",
            "Episode 354 | Epsilon   0.02 | Batch Size 70800 | Episode Return 9.73e+06 | Evaluation Score 3.03e+07\n",
            "Episode 355 | Epsilon   0.02 | Batch Size 71000 | Episode Return 2.47e+07 | Evaluation Score 1.75e+07\n",
            "Episode 356 | Epsilon   0.02 | Batch Size 71200 | Episode Return 4.78e+06 | Evaluation Score 1.49e+07\n",
            "Episode 357 | Epsilon   0.02 | Batch Size 71400 | Episode Return 2.22e+07 | Evaluation Score 2.33e+07\n",
            "Episode 358 | Epsilon   0.02 | Batch Size 71600 | Episode Return 1.82e+07 | Evaluation Score 2.78e+07\n",
            "Episode 359 | Epsilon   0.02 | Batch Size 71800 | Episode Return 2.46e+06 | Evaluation Score 1.92e+07\n",
            "Episode 360 | Epsilon   0.02 | Batch Size 72000 | Episode Return 1.72e+07 | Evaluation Score 1.74e+07\n",
            "Episode 361 | Epsilon   0.02 | Batch Size 72200 | Episode Return 5.61e+06 | Evaluation Score 1.11e+07\n",
            "Episode 362 | Epsilon   0.02 | Batch Size 72400 | Episode Return 4.75e+06 | Evaluation Score 2.27e+07\n",
            "Episode 363 | Epsilon   0.02 | Batch Size 72600 | Episode Return 2.17e+07 | Evaluation Score 7.84e+06\n",
            "Episode 364 | Epsilon   0.02 | Batch Size 72800 | Episode Return 2.73e+07 | Evaluation Score 7.73e+06\n",
            "Episode 365 | Epsilon   0.02 | Batch Size 73000 | Episode Return 1.28e+07 | Evaluation Score 1.79e+07\n",
            "Episode 366 | Epsilon   0.02 | Batch Size 73200 | Episode Return 1.66e+07 | Evaluation Score 2.68e+07\n",
            "Episode 367 | Epsilon   0.02 | Batch Size 73400 | Episode Return 2.95e+07 | Evaluation Score 1.73e+07\n",
            "Episode 368 | Epsilon   0.02 | Batch Size 73600 | Episode Return 1.40e+07 | Evaluation Score 3.00e+07\n",
            "Episode 369 | Epsilon   0.02 | Batch Size 73800 | Episode Return 2.81e+07 | Evaluation Score 2.57e+07\n",
            "Episode 370 | Epsilon   0.02 | Batch Size 74000 | Episode Return 2.18e+07 | Evaluation Score 1.02e+07\n",
            "Episode 371 | Epsilon   0.02 | Batch Size 74200 | Episode Return 3.75e+06 | Evaluation Score 7.15e+06\n",
            "Episode 372 | Epsilon   0.02 | Batch Size 74400 | Episode Return 2.23e+07 | Evaluation Score 1.67e+07\n",
            "Episode 373 | Epsilon   0.02 | Batch Size 74600 | Episode Return 2.67e+07 | Evaluation Score 7.48e+06\n",
            "Episode 374 | Epsilon   0.02 | Batch Size 74800 | Episode Return 2.09e+07 | Evaluation Score 8.31e+06\n",
            "Episode 375 | Epsilon   0.02 | Batch Size 75000 | Episode Return 5.83e+05 | Evaluation Score 7.79e+06\n",
            "Episode 376 | Epsilon   0.02 | Batch Size 75200 | Episode Return 1.58e+07 | Evaluation Score 1.18e+07\n",
            "Episode 377 | Epsilon   0.02 | Batch Size 75400 | Episode Return 2.18e+07 | Evaluation Score 8.53e+06\n",
            "Episode 378 | Epsilon   0.02 | Batch Size 75600 | Episode Return 1.50e+07 | Evaluation Score 1.22e+07\n",
            "Episode 379 | Epsilon   0.02 | Batch Size 75800 | Episode Return 9.94e+06 | Evaluation Score 1.60e+07\n",
            "Episode 380 | Epsilon   0.02 | Batch Size 76000 | Episode Return 1.26e+07 | Evaluation Score 9.46e+06\n",
            "Episode 381 | Epsilon   0.02 | Batch Size 76200 | Episode Return 3.70e+06 | Evaluation Score 9.02e+06\n",
            "Episode 382 | Epsilon   0.02 | Batch Size 76400 | Episode Return 1.53e+06 | Evaluation Score 2.27e+07\n",
            "Episode 383 | Epsilon   0.02 | Batch Size 76600 | Episode Return 7.68e+06 | Evaluation Score 1.79e+07\n",
            "Episode 384 | Epsilon   0.02 | Batch Size 76800 | Episode Return 1.55e+07 | Evaluation Score 1.89e+07\n",
            "Episode 385 | Epsilon   0.02 | Batch Size 77000 | Episode Return 2.60e+07 | Evaluation Score 1.31e+07\n",
            "Episode 386 | Epsilon   0.02 | Batch Size 77200 | Episode Return 3.05e+07 | Evaluation Score 9.72e+06\n",
            "Episode 387 | Epsilon   0.02 | Batch Size 77400 | Episode Return 1.50e+07 | Evaluation Score 2.29e+07\n",
            "Episode 388 | Epsilon   0.02 | Batch Size 77600 | Episode Return 2.00e+07 | Evaluation Score 1.00e+07\n",
            "Episode 389 | Epsilon   0.02 | Batch Size 77800 | Episode Return 1.11e+07 | Evaluation Score 2.02e+07\n",
            "Episode 390 | Epsilon   0.02 | Batch Size 78000 | Episode Return 1.32e+07 | Evaluation Score 3.21e+07\n",
            "Episode 391 | Epsilon   0.02 | Batch Size 78200 | Episode Return 2.71e+07 | Evaluation Score 9.35e+06\n",
            "Episode 392 | Epsilon   0.02 | Batch Size 78400 | Episode Return 1.09e+07 | Evaluation Score 2.23e+07\n",
            "Episode 393 | Epsilon   0.02 | Batch Size 78600 | Episode Return 1.26e+07 | Evaluation Score 6.10e+07\n",
            "Episode 394 | Epsilon   0.02 | Batch Size 78800 | Episode Return 4.36e+07 | Evaluation Score 1.34e+07\n",
            "Episode 395 | Epsilon   0.02 | Batch Size 79000 | Episode Return 2.84e+07 | Evaluation Score 1.81e+07\n",
            "Episode 396 | Epsilon   0.02 | Batch Size 79200 | Episode Return 2.36e+07 | Evaluation Score 1.49e+07\n",
            "Episode 397 | Epsilon   0.02 | Batch Size 79400 | Episode Return 6.27e+06 | Evaluation Score 2.74e+07\n",
            "Episode 398 | Epsilon   0.02 | Batch Size 79600 | Episode Return 2.53e+06 | Evaluation Score 3.75e+07\n",
            "Episode 399 | Epsilon   0.02 | Batch Size 79800 | Episode Return 2.24e+07 | Evaluation Score 2.30e+07\n",
            "Episode 400 | Epsilon   0.02 | Batch Size 80000 | Episode Return 2.23e+06 | Evaluation Score 5.24e+07\n",
            "Episode 401 | Epsilon   0.02 | Batch Size 80200 | Episode Return 2.51e+06 | Evaluation Score 2.50e+07\n",
            "Episode 402 | Epsilon   0.02 | Batch Size 80400 | Episode Return 1.67e+07 | Evaluation Score 5.83e+07\n",
            "Episode 403 | Epsilon   0.02 | Batch Size 80600 | Episode Return 7.24e+06 | Evaluation Score 1.32e+07\n",
            "Episode 404 | Epsilon   0.02 | Batch Size 80800 | Episode Return 1.19e+07 | Evaluation Score 9.57e+06\n",
            "Episode 405 | Epsilon   0.02 | Batch Size 81000 | Episode Return 2.18e+07 | Evaluation Score 1.48e+07\n",
            "Episode 406 | Epsilon   0.02 | Batch Size 81200 | Episode Return 1.18e+07 | Evaluation Score 8.35e+06\n",
            "Episode 407 | Epsilon   0.02 | Batch Size 81400 | Episode Return 1.38e+09 | Evaluation Score 2.67e+07\n",
            "Episode 408 | Epsilon   0.02 | Batch Size 81600 | Episode Return 2.29e+07 | Evaluation Score 9.52e+06\n",
            "Episode 409 | Epsilon   0.02 | Batch Size 81800 | Episode Return 1.32e+10 | Evaluation Score 7.73e+06\n",
            "Episode 410 | Epsilon   0.02 | Batch Size 82000 | Episode Return 2.18e+07 | Evaluation Score 6.80e+06\n",
            "Episode 411 | Epsilon   0.02 | Batch Size 82200 | Episode Return 1.28e+07 | Evaluation Score 9.24e+06\n",
            "Episode 412 | Epsilon   0.02 | Batch Size 82400 | Episode Return 2.38e+07 | Evaluation Score 9.33e+06\n",
            "Episode 413 | Epsilon   0.02 | Batch Size 82600 | Episode Return 7.01e+07 | Evaluation Score 7.07e+06\n",
            "Episode 414 | Epsilon   0.02 | Batch Size 82800 | Episode Return 2.11e+07 | Evaluation Score 7.71e+06\n",
            "Episode 415 | Epsilon   0.02 | Batch Size 83000 | Episode Return 7.90e+06 | Evaluation Score 7.31e+06\n",
            "Episode 416 | Epsilon   0.02 | Batch Size 83200 | Episode Return 5.53e+06 | Evaluation Score 8.47e+06\n",
            "Episode 417 | Epsilon   0.02 | Batch Size 83400 | Episode Return 6.39e+09 | Evaluation Score 8.09e+06\n",
            "Episode 418 | Epsilon   0.02 | Batch Size 83600 | Episode Return 5.49e+09 | Evaluation Score 6.97e+06\n",
            "Episode 419 | Epsilon   0.02 | Batch Size 83800 | Episode Return 6.23e+07 | Evaluation Score 8.55e+06\n",
            "Episode 420 | Epsilon   0.02 | Batch Size 84000 | Episode Return 6.32e+06 | Evaluation Score 9.43e+06\n",
            "Episode 421 | Epsilon   0.02 | Batch Size 84200 | Episode Return 2.35e+08 | Evaluation Score 6.62e+06\n",
            "Episode 422 | Epsilon   0.02 | Batch Size 84400 | Episode Return 2.01e+07 | Evaluation Score 6.99e+06\n",
            "Episode 423 | Epsilon   0.02 | Batch Size 84600 | Episode Return 3.88e+08 | Evaluation Score 1.46e+07\n",
            "Episode 424 | Epsilon   0.02 | Batch Size 84800 | Episode Return 8.70e+06 | Evaluation Score 6.80e+06\n",
            "Episode 425 | Epsilon   0.02 | Batch Size 85000 | Episode Return 1.73e+07 | Evaluation Score 1.40e+07\n",
            "Episode 426 | Epsilon   0.02 | Batch Size 85200 | Episode Return 2.15e+07 | Evaluation Score 6.70e+06\n",
            "Episode 427 | Epsilon   0.02 | Batch Size 85400 | Episode Return 5.69e+09 | Evaluation Score 6.52e+06\n",
            "Episode 428 | Epsilon   0.02 | Batch Size 85600 | Episode Return 6.49e+09 | Evaluation Score 7.76e+06\n",
            "Episode 429 | Epsilon   0.02 | Batch Size 85800 | Episode Return 7.23e+06 | Evaluation Score 6.98e+06\n",
            "Episode 430 | Epsilon   0.02 | Batch Size 86000 | Episode Return 5.93e+06 | Evaluation Score 6.67e+06\n",
            "Episode 431 | Epsilon   0.02 | Batch Size 86200 | Episode Return 5.71e+06 | Evaluation Score 1.94e+07\n",
            "Episode 432 | Epsilon   0.02 | Batch Size 86400 | Episode Return 1.43e+07 | Evaluation Score 2.09e+07\n",
            "Episode 433 | Epsilon   0.02 | Batch Size 86600 | Episode Return 6.23e+08 | Evaluation Score 8.38e+06\n",
            "Episode 434 | Epsilon   0.02 | Batch Size 86800 | Episode Return 4.60e+09 | Evaluation Score 9.50e+06\n",
            "Episode 435 | Epsilon   0.02 | Batch Size 87000 | Episode Return 7.27e+09 | Evaluation Score 1.07e+07\n",
            "Episode 436 | Epsilon   0.02 | Batch Size 87200 | Episode Return 6.00e+09 | Evaluation Score 1.01e+07\n",
            "Episode 437 | Epsilon   0.02 | Batch Size 87400 | Episode Return 7.02e+09 | Evaluation Score 1.01e+07\n",
            "Episode 438 | Epsilon   0.02 | Batch Size 87600 | Episode Return 3.58e+07 | Evaluation Score 2.21e+07\n",
            "Episode 439 | Epsilon   0.02 | Batch Size 87800 | Episode Return 9.55e+09 | Evaluation Score 2.21e+07\n",
            "Episode 440 | Epsilon   0.02 | Batch Size 88000 | Episode Return 4.29e+09 | Evaluation Score 2.45e+07\n",
            "Episode 441 | Epsilon   0.02 | Batch Size 88200 | Episode Return 4.24e+07 | Evaluation Score 4.65e+07\n",
            "Episode 442 | Epsilon   0.02 | Batch Size 88400 | Episode Return 8.67e+09 | Evaluation Score 5.31e+07\n",
            "Episode 443 | Epsilon   0.02 | Batch Size 88600 | Episode Return 6.12e+09 | Evaluation Score 1.61e+07\n",
            "Episode 444 | Epsilon   0.02 | Batch Size 88800 | Episode Return 1.45e+07 | Evaluation Score 2.22e+07\n",
            "Episode 445 | Epsilon   0.02 | Batch Size 89000 | Episode Return 1.27e+10 | Evaluation Score 5.37e+07\n",
            "Episode 446 | Epsilon   0.02 | Batch Size 89200 | Episode Return 6.61e+09 | Evaluation Score 4.72e+07\n",
            "Episode 447 | Epsilon   0.02 | Batch Size 89400 | Episode Return 3.84e+08 | Evaluation Score 6.75e+07\n",
            "Episode 448 | Epsilon   0.02 | Batch Size 89600 | Episode Return 5.86e+09 | Evaluation Score 6.78e+07\n",
            "Episode 449 | Epsilon   0.02 | Batch Size 89800 | Episode Return 2.23e+09 | Evaluation Score 3.19e+07\n",
            "Episode 450 | Epsilon   0.02 | Batch Size 90000 | Episode Return 1.06e+10 | Evaluation Score 5.92e+07\n",
            "Episode 451 | Epsilon   0.02 | Batch Size 90200 | Episode Return 1.69e+10 | Evaluation Score 4.34e+07\n",
            "Episode 452 | Epsilon   0.02 | Batch Size 90400 | Episode Return 2.12e+10 | Evaluation Score 5.06e+07\n",
            "Episode 453 | Epsilon   0.02 | Batch Size 90600 | Episode Return 1.88e+10 | Evaluation Score 3.10e+07\n",
            "Episode 454 | Epsilon   0.02 | Batch Size 90800 | Episode Return 3.44e+07 | Evaluation Score 2.94e+07\n",
            "Episode 455 | Epsilon   0.02 | Batch Size 91000 | Episode Return 1.15e+10 | Evaluation Score 3.51e+07\n",
            "Episode 456 | Epsilon   0.02 | Batch Size 91200 | Episode Return 2.88e+07 | Evaluation Score 4.82e+07\n",
            "Episode 457 | Epsilon   0.02 | Batch Size 91400 | Episode Return 1.25e+10 | Evaluation Score 2.22e+07\n",
            "Episode 458 | Epsilon   0.02 | Batch Size 91600 | Episode Return 1.68e+10 | Evaluation Score 4.97e+07\n",
            "Episode 459 | Epsilon   0.02 | Batch Size 91800 | Episode Return 8.08e+09 | Evaluation Score 1.82e+07\n",
            "Episode 460 | Epsilon   0.02 | Batch Size 92000 | Episode Return 3.10e+09 | Evaluation Score 1.47e+07\n",
            "Episode 461 | Epsilon   0.02 | Batch Size 92200 | Episode Return 5.05e+08 | Evaluation Score 8.15e+07\n",
            "Episode 462 | Epsilon   0.02 | Batch Size 92400 | Episode Return 3.28e+09 | Evaluation Score 7.92e+07\n",
            "Episode 463 | Epsilon   0.02 | Batch Size 92600 | Episode Return 1.32e+10 | Evaluation Score 9.20e+07\n",
            "Episode 464 | Epsilon   0.02 | Batch Size 92800 | Episode Return 1.37e+10 | Evaluation Score 6.91e+07\n",
            "Episode 465 | Epsilon   0.02 | Batch Size 93000 | Episode Return 3.25e+07 | Evaluation Score 1.18e+08\n",
            "Episode 466 | Epsilon   0.02 | Batch Size 93200 | Episode Return 4.17e+08 | Evaluation Score 8.82e+07\n",
            "Episode 467 | Epsilon   0.02 | Batch Size 93400 | Episode Return 2.21e+07 | Evaluation Score 1.25e+08\n",
            "Episode 468 | Epsilon   0.02 | Batch Size 93600 | Episode Return 1.30e+10 | Evaluation Score 1.18e+08\n",
            "Episode 469 | Epsilon   0.02 | Batch Size 93800 | Episode Return 1.77e+10 | Evaluation Score 8.22e+07\n",
            "Episode 470 | Epsilon   0.02 | Batch Size 94000 | Episode Return 1.40e+10 | Evaluation Score 7.70e+07\n",
            "Episode 471 | Epsilon   0.02 | Batch Size 94200 | Episode Return 2.49e+10 | Evaluation Score 8.57e+07\n",
            "Episode 472 | Epsilon   0.02 | Batch Size 94400 | Episode Return 5.62e+09 | Evaluation Score 6.66e+07\n",
            "Episode 473 | Epsilon   0.02 | Batch Size 94600 | Episode Return 9.32e+09 | Evaluation Score 7.71e+07\n",
            "Episode 474 | Epsilon   0.02 | Batch Size 94800 | Episode Return 1.08e+10 | Evaluation Score 6.35e+07\n",
            "Episode 475 | Epsilon   0.02 | Batch Size 95000 | Episode Return 6.20e+07 | Evaluation Score 4.34e+07\n",
            "Episode 476 | Epsilon   0.02 | Batch Size 95200 | Episode Return 1.31e+08 | Evaluation Score 5.31e+07\n",
            "Episode 477 | Epsilon   0.02 | Batch Size 95400 | Episode Return 6.30e+07 | Evaluation Score 4.51e+07\n",
            "Episode 478 | Epsilon   0.02 | Batch Size 95600 | Episode Return 5.64e+07 | Evaluation Score 3.99e+07\n",
            "Episode 479 | Epsilon   0.02 | Batch Size 95800 | Episode Return 1.58e+09 | Evaluation Score 4.01e+07\n",
            "Episode 480 | Epsilon   0.02 | Batch Size 96000 | Episode Return 4.45e+07 | Evaluation Score 4.07e+07\n",
            "Episode 481 | Epsilon   0.02 | Batch Size 96200 | Episode Return 3.81e+08 | Evaluation Score 4.53e+07\n",
            "Episode 482 | Epsilon   0.02 | Batch Size 96400 | Episode Return 1.52e+10 | Evaluation Score 4.57e+07\n",
            "Episode 483 | Epsilon   0.02 | Batch Size 96600 | Episode Return 1.08e+09 | Evaluation Score 3.19e+07\n",
            "Episode 484 | Epsilon   0.02 | Batch Size 96800 | Episode Return 4.83e+07 | Evaluation Score 3.47e+07\n",
            "Episode 485 | Epsilon   0.02 | Batch Size 97000 | Episode Return 1.55e+08 | Evaluation Score 4.29e+07\n",
            "Episode 486 | Epsilon   0.02 | Batch Size 97200 | Episode Return 1.90e+09 | Evaluation Score 3.79e+07\n",
            "Episode 487 | Epsilon   0.02 | Batch Size 97400 | Episode Return 3.62e+07 | Evaluation Score 1.79e+07\n",
            "Episode 488 | Epsilon   0.02 | Batch Size 97600 | Episode Return 2.93e+07 | Evaluation Score 2.95e+07\n",
            "Episode 489 | Epsilon   0.02 | Batch Size 97800 | Episode Return 1.25e+08 | Evaluation Score 2.29e+07\n",
            "Episode 490 | Epsilon   0.02 | Batch Size 98000 | Episode Return 7.00e+09 | Evaluation Score 2.84e+07\n",
            "Episode 491 | Epsilon   0.02 | Batch Size 98200 | Episode Return 3.51e+07 | Evaluation Score 2.63e+07\n",
            "Episode 492 | Epsilon   0.02 | Batch Size 98400 | Episode Return 3.41e+07 | Evaluation Score 2.90e+07\n",
            "Episode 493 | Epsilon   0.02 | Batch Size 98600 | Episode Return 2.74e+07 | Evaluation Score 1.98e+07\n",
            "Episode 494 | Epsilon   0.02 | Batch Size 98800 | Episode Return 7.43e+07 | Evaluation Score 1.63e+07\n",
            "Episode 495 | Epsilon   0.02 | Batch Size 99000 | Episode Return 4.06e+07 | Evaluation Score 1.94e+07\n",
            "Episode 496 | Epsilon   0.02 | Batch Size 99200 | Episode Return 9.70e+07 | Evaluation Score 2.44e+07\n",
            "Episode 497 | Epsilon   0.02 | Batch Size 99400 | Episode Return 2.20e+07 | Evaluation Score 2.22e+07\n",
            "Episode 498 | Epsilon   0.02 | Batch Size 99600 | Episode Return 3.93e+07 | Evaluation Score 1.86e+07\n",
            "Episode 499 | Epsilon   0.02 | Batch Size 99800 | Episode Return 2.85e+07 | Evaluation Score 2.11e+07\n",
            "Episode 500 | Epsilon   0.02 | Batch Size 100000 | Episode Return 3.46e+07 | Evaluation Score 2.05e+07\n",
            "Score agent: 30048290286.373714\n",
            "Score agent with domain randomization: 26116554933.707973\n"
          ]
        }
      ],
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file = Path(\"score.txt\")\n",
        "    if not file.is_file():\n",
        "        seed_everything(seed=42)\n",
        "        # Initialization of the agent. Replace DummyAgent with your custom agent implementation.\n",
        "        agent = ProjectAgent()\n",
        "        #agent.load(path)\n",
        "        agent.train(500, fine_tuning=False)\n",
        "        agent.save(path)\n",
        "\n",
        "        # Evaluate agent and write score.\n",
        "        score_agent: float = evaluate_HIV(agent=agent, nb_episode=5)\n",
        "        score_agent_dr: float = evaluate_HIV_population(agent=agent, nb_episode=20)\n",
        "        print(f\"Score agent: {score_agent}\")\n",
        "        print(f\"Score agent with domain randomization: {score_agent_dr}\")\n",
        "        with open(file= path + \"score.txt\", mode=\"w\") as f:\n",
        "            f.write(f\"{score_agent}\\n{score_agent_dr}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hTfyuCYm75JC"
      ],
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
